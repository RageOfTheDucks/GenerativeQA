{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Generative Question Answering in low performance environments\n","\n","# Introduction\n","\n","During the NLP course we had to produce, unsing the Hugging Face transformers library, a simple Open Generative Question Answering (QA) model. The task was also constraint in using a specific transformer-based model, limiting the possible approaches. At the end, general results were not great, leading me in wanting to try different approaches to better understand this complex and still less explored subject.\n","\n","## Subject of analysis\n","\n","As stated before, here we are going to analyze the Question Answering task, trying to produce a model which can retrieve the answer from a given question and its context.\n","\n","More precisely, the [main variants](https://huggingface.co/tasks/question-answering) of this task are:\n","\n","- **Extractive QA**: \n","\n","    The model extracts the answer from a context. The context is provided as text passage. This is usually solved with BERT-like models.  \n","\n","- **Open Generative QA**: \n","\n","    The model generates free text directly based on the context.\n","\n","- **Closed Generative QA**: \n","\n","    In this case, no context is provided. The answer is completely generated by a model.\n","\n","The main objective of this notebook is to explore Open Generative QA and understand how can it be improved in simple and limited developing environment such as Colab.\n","\n","## Generative QA\n","\n","Answering questions in natural language can be beneficial to a variety of QA applications, and has led to the development of smart devices such as Siri, Cortana and Alexa. However, compared to answer extraction, answer generation for reading comprehension is more challenging, and has been less explored.\n","\n","As stated in the [Li et al.](https://aclanthology.org/2021.acl-short.118/) paper, although much work has been done in neural language generation for summarization, out-of-control generation still has its problems, such as the \"Semantic drift\" of the answer from the passage (the answer has little or no semantic affiliation with the question).\n","\n","\n","In the first part of the notebook we are going to analyze one of the most performing model in generative QA, while in the second half we are going to analyze if an ensamble of specific models could preform better in this low resources envirnoments.\n","\n","## Model structure\n","\n","We are going to experiment with transformer-based models to define a final architecture of the form:\n","\n","A = f_θ(Q,P)\n","\n","where:\n","- f is the transformer-based model we have to define.\n","- θ parameters.\n","- Q question\n","- P Passage or context of the question\n","- A the generated answer"],"metadata":{"id":"YsuJl3tZTxVo"}},{"cell_type":"markdown","source":["# Initial Setup\n","\n","## Imports"],"metadata":{"id":"9GmV3MhpTxVw"}},{"cell_type":"code","source":["!pip install transformers --upgrade\n","!pip install datasets\n","!pip install evaluate"],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-09T09:22:37.130479Z","iopub.execute_input":"2023-02-09T09:22:37.131383Z","iopub.status.idle":"2023-02-09T09:23:18.603384Z","shell.execute_reply.started":"2023-02-09T09:22:37.131260Z","shell.execute_reply":"2023-02-09T09:23:18.601962Z"},"trusted":true,"id":"ZpU197j_TxVx","outputId":"9dcb3c64-c749-4b26-eb9c-93735217fc2b"},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nCollecting transformers\n  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nCollecting huggingface-hub<1.0,>=0.11.0\n  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nInstalling collected packages: huggingface-hub, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.10.1\n    Uninstalling huggingface-hub-0.10.1:\n      Successfully uninstalled huggingface-hub-0.10.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.20.1\n    Uninstalling transformers-4.20.1:\n      Successfully uninstalled transformers-4.20.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncached-path 1.1.6 requires huggingface-hub<0.11.0,>=0.8.1, but you have huggingface-hub 0.12.0 which is incompatible.\nallennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.26.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.12.0 transformers-4.26.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.12.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (6.0.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (23.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.12.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2023.1.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (5.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2022.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":["# File and download imports\n","import os\n","import urllib.request\n","import json\n","from tqdm import tqdm\n","\n","# Dataframe management\n","import pandas as pd \n","\n","# Data manipulation\n","import numpy as np  \n","import random\n","\n","# Classification with sklearn\n","from sklearn import metrics\n","from sklearn.utils import resample\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import ComplementNB, MultinomialNB\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_validate\n","\n","# Convert to HuggingFace dataset\n","import pyarrow as pa\n","import datasets\n","\n","# Transformers\n","import transformers\n","from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, TFT5ForConditionalGeneration, TFAutoModelForQuestionAnswering, AdamWeightDecay, DataCollatorForSeq2Seq\n","\n","# Evaluation\n","from evaluate import load\n","\n","# Tensorflow\n","import tensorflow as tf"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:23:18.606176Z","iopub.execute_input":"2023-02-09T09:23:18.607114Z","iopub.status.idle":"2023-02-09T09:23:31.101689Z","shell.execute_reply.started":"2023-02-09T09:23:18.607057Z","shell.execute_reply":"2023-02-09T09:23:31.100751Z"},"trusted":true,"id":"JZqUbR-cTxV0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Download the [CoQA](https://stanfordnlp.github.io/coqa/) dataset\n","\n","Also the [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) could have been utilized but CoQA was ultimately chones due to:\n","\n","- Its complexity due to the presence of interconnected questions\n","- It was the same dataset used in the NLP course assignment, creating a good comparison"],"metadata":{"id":"ceBesFVETxV1"}},{"cell_type":"code","source":["class DownloadProgressBar(tqdm):\n","    def update_to(self, b=1, bsize=1, tsize=None):\n","        if tsize is not None:\n","            self.total = tsize\n","        self.update(b * bsize - self.n)\n","        \n","def download_url(url, output_path):\n","    with DownloadProgressBar(unit='B', unit_scale=True,\n","                             miniters=1, desc=url.split('/')[-1]) as t:\n","        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n","\n","def download_data(data_path, url_path, suffix):    \n","    if not os.path.exists(data_path):\n","        os.makedirs(data_path)\n","        \n","    data_path = os.path.join(data_path, f'{suffix}.json')\n","\n","    if not os.path.exists(data_path):\n","        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n","        download_url(url=url_path, output_path=data_path)\n","        print(\"Download completed!\")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:23:31.103198Z","iopub.execute_input":"2023-02-09T09:23:31.103873Z","iopub.status.idle":"2023-02-09T09:23:31.115240Z","shell.execute_reply.started":"2023-02-09T09:23:31.103836Z","shell.execute_reply":"2023-02-09T09:23:31.114330Z"},"trusted":true,"id":"HNznSYHTTxV1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path='coqa'\n","\n","# Train data\n","train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n","download_data(data_path=data_path, url_path=train_url, suffix='train')\n","\n","# Test data\n","test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n","download_data(data_path=data_path, url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:23:31.125984Z","iopub.execute_input":"2023-02-09T09:23:31.128520Z","iopub.status.idle":"2023-02-09T09:23:37.666137Z","shell.execute_reply.started":"2023-02-09T09:23:31.128479Z","shell.execute_reply":"2023-02-09T09:23:37.665209Z"},"trusted":true,"id":"2fWq5ephTxV2","outputId":"b31bebe4-2c35-4896-9635-1de4b45c97fa"},"execution_count":null,"outputs":[{"name":"stdout","text":"Downloading CoQA train data split... (it may take a while)\n","output_type":"stream"},{"name":"stderr","text":"coqa-train-v1.0.json: 49.0MB [00:05, 8.91MB/s]                            \n","output_type":"stream"},{"name":"stdout","text":"Download completed!\nDownloading CoQA test data split... (it may take a while)\n","output_type":"stream"},{"name":"stderr","text":"coqa-dev-v1.0.json: 9.09MB [00:01, 9.09MB/s]                            ","output_type":"stream"},{"name":"stdout","text":"Download completed!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":["# Data Inspection\n","\n","## Dataset Statistics\n","\n","* **127k** QA pairs.\n","* **8k** conversations.\n","* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n","* Average conversation length: **15 turns** (i.e., QA pairs).\n","* Almost **half** of CoQA questions refer back to **conversational history**.\n","* Only **train** and **validation** sets are available.\n","\n","## Dataset snippet\n","\n","The dataset is stored in JSON format. Each dialogue is represented as follows:\n","\n","```\n","{\n","    \"source\": \"mctest\",\n","    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n","    \"filename\": \"mc160.test.41\",\n","    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n","    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n","    \"questions\": [\n","        {\n","            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n","            \"turn_id\": 1\n","        },\n","        {\n","            \"input_text\": \"Where did she live?\",  % <-- $Q_2$\n","            \"turn_id\": 2\n","        },\n","        [...]\n","    ],\n","    \"answers\": [\n","        {\n","            \"span_start\": 59,   % <-- $R_1$ start index\n","            \"spand_end\": 93,    % <-- $R_1$ end index\n","            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n","            \"input_text\" \"white\",   % <-- $A_1$      \n","            \"turn_id\": 1\n","        },\n","        [...]\n","    ]\n","}\n","```\n","\n","For each source we have multiples stories and, for each one of them, multiple QAs.\n","\n","Each answer will include:\n","\n","- The span of the answer\n","- The text of the answer\n","- Its id\n","\n","Each dialogue also contains an additional field ```additional_answers```. For simplicity, we are going to **ignore** this field, taking only the original answer.\n","\n","Furthermore, CoQA contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs.\n","\n","## Dataframe manipulation"],"metadata":{"id":"oAkYX8LNTxV3"}},{"cell_type":"code","source":["# Random seed function\n","def set_random_seeds(seed: int):\n","  # Sets the random seed for reproducibility\n","  os.environ['PYTHONHASHSEED']=str(seed)\n","  os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  tf.random.set_seed(seed)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:23:37.667800Z","iopub.execute_input":"2023-02-09T09:23:37.668513Z","iopub.status.idle":"2023-02-09T09:23:37.695795Z","shell.execute_reply.started":"2023-02-09T09:23:37.668475Z","shell.execute_reply":"2023-02-09T09:23:37.690589Z"},"trusted":true,"id":"Q2nrd-0JTxV3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To better handle huggingface transformers, we convert our dataframes to a dict of hg datasets\n","def convert_to_hg_dataset(coulmns_to_remove, train, val):\n","    hg_train = datasets.Dataset(pa.Table.from_pandas(train.drop(coulmns_to_remove, axis=1)))\n","    hg_val = datasets.Dataset(pa.Table.from_pandas(val.drop(coulmns_to_remove, axis=1)))\n","\n","    hg_ds = datasets.DatasetDict({\"train\":hg_train,\"val\":hg_val})\n","\n","    return hg_ds"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:41.829790Z","iopub.execute_input":"2023-02-09T09:25:41.830247Z","iopub.status.idle":"2023-02-09T09:25:41.854248Z","shell.execute_reply.started":"2023-02-09T09:25:41.830205Z","shell.execute_reply":"2023-02-09T09:25:41.853407Z"},"trusted":true,"id":"maRT5wtYTxV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def json_to_pandas(file_name):\n","  \"\"\"\n","    Given the name of the json file downloaded from CoQA, tranform its data\n","    into a pandas dataframes\n","\n","    Param:\n","        - file_name: name of the json file to transform\n","\n","    Return:\n","        - df_qa: dataframe containing all the stories, questions, R1s and answers\n","    \"\"\"\n","\n","  # Get the json fie\n","  file_path = data_path+'/'+file_name\n","  json_file = open(file_path).read()\n","  json_dict = json.loads(json_file)\n","\n","  # Part of the dict with our data\n","  json_data = json_dict['data']\n","\n","  # Len of our list of dict\n","  l = sum(1 for a in json_data)\n","\n","  question_answer = []\n","\n","  # Loop into the json dict\n","  for i in range(l):\n","\n","    # Len of question/answer\n","    l_qa = sum(1 for a in json_data[i]['questions'])\n","\n","    # Iterate on question/answer for the current story\n","    for j in range(l_qa):\n","      qa = {}\n","      qa['story_id'] = i\n","      qa['story'] = json_data[i]['story']\n","      qa['question'] = json_data[i]['questions'][j]['input_text']\n","      qa['answer'] = json_data[i]['answers'][j]['input_text']\n","      qa['R1_start'] = json_data[i]['answers'][j]['span_start']\n","      qa['R1_end'] = json_data[i]['answers'][j]['span_end']\n","      qa['R1'] = json_data[i]['answers'][j]['span_text']\n","      question_answer.append(qa)\n","\n","  # Create dataframe\n","  df_qa = pd.DataFrame(question_answer)\n","\n","  # Remove unkown answers\n","  # Questions wthout answers have: answer = unkown, R1_start = -1. R1_end = -1, R1 = unkown\n","  df_qa = df_qa[df_qa.R1_start != -1]\n","\n","  return df_qa"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:47.544306Z","iopub.execute_input":"2023-02-09T09:25:47.544918Z","iopub.status.idle":"2023-02-09T09:25:47.557650Z","shell.execute_reply.started":"2023-02-09T09:25:47.544874Z","shell.execute_reply":"2023-02-09T09:25:47.556495Z"},"trusted":true,"id":"ShB-pjvPTxV5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since CoQA only provides train and test datasets, we need to produce the validation dataset.\n","\n","We decided to perform the split in the training set such that:\n","\n","- The split can be freely chosen, in our case we utilized a 80-20 split.\n","- The splits must be performed such that a dialogue appears in one split only (i.e., split at dialogue level)"],"metadata":{"id":"PgXwxCnRTxV6"}},{"cell_type":"code","source":["# Reproducibility\n","random.seed(42)\n","\n","# Split function\n","def train_val_split(dataframe, split, rand):\n","  \"\"\"\n","    Perform train/val split based on the stories, correctly having all the \n","    question of a given story in the same split\n","\n","    Param:\n","        - datafram: dataframe to perform the split\n","        - split: percentage of the split (IN DECIMAL FORMAT)\n","        - rand: True for random split, False simple sequential split\n","\n","    Return:\n","        - df_train: train dataframe\n","        - df_val: validation dataframe\n","    \"\"\"\n","\n","  # Input mishandling\n","  if not isinstance(rand, (bool)):\n","    raise ValueError(\"Rand must be a boolean value\")\n","\n","  if not 0 <= split <= 1:\n","    raise ValueError(\"Split must be between 0.0 and 1.0\")\n","\n","\n","  # Get total number of stories\n","  number_of_stories = dataframe['story_id'].iloc[-1]\n","\n","  # Randomly choose stories\n","  split_id = int(number_of_stories*split)\n","\n","  if rand == True:\n","    split_list = random.sample(range(0, number_of_stories), split_id)\n","  else:\n","    split_list = [*range(0, split_id)]\n","\n","  # Create train and val dataframes\n","  df_train = dataframe[dataframe['story_id'].isin(split_list)]\n","  df_val = dataframe[dataframe[\"story_id\"].isin(split_list) == False]\n","\n","  return df_train.reset_index().drop('index', axis = 1), df_val.reset_index().drop('index', axis = 1)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:47.560013Z","iopub.execute_input":"2023-02-09T09:25:47.560481Z","iopub.status.idle":"2023-02-09T09:25:47.573063Z","shell.execute_reply.started":"2023-02-09T09:25:47.560437Z","shell.execute_reply":"2023-02-09T09:25:47.571972Z"},"trusted":true,"id":"ayhSQwbETxV7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We decided to introduce in our dataframes one additional column `y` which defines if a question is an open question (0) or a yes-or-no question (1).\n","\n","This additional classification will be later explained in the ensamble part."],"metadata":{"id":"m79TGQeRTxV8"}},{"cell_type":"code","source":["# Train\n","df_train_qa = json_to_pandas('train.json')\n","\n","# Take the answers\n","df_answers = df_train_qa['answer'].copy()\n","\n","# Set the answers to lowercase to better manipulate them\n","df_train_qa['answer'] = df_train_qa['answer'].apply(str.lower)\n","\n","# Insert a new column\n","df_train_qa['y'] = df_train_qa.apply(lambda x: 1 if((x['answer'] == 'yes' or x['answer'] == 'yes.') or (x['answer'] == 'no' or x['answer'] == 'no.')) else 0, axis=1)\n","\n","# Reset the answers in the original format\n","df_train_qa = df_train_qa.drop(['answer'], axis = 1)\n","df_train_qa = df_train_qa.join(df_answers)\n","\n","\n","# Test\n","df_test_qa = json_to_pandas('test.json')\n","\n","# Take the answers\n","df_answers = df_test_qa['answer'].copy()\n","\n","# Set the answers to lowercase to better manipulate them\n","df_test_qa['answer'] = df_test_qa['answer'].apply(str.lower)\n","\n","# Insert a new column\n","df_test_qa['y'] = df_test_qa.apply(lambda x: 1 if((x['answer'] == 'yes' or x['answer'] == 'yes.') or (x['answer'] == 'no' or x['answer'] == 'no.')) else 0, axis=1)\n","\n","# Reset the answers in the original format\n","df_test_qa = df_test_qa.drop(['answer'], axis = 1)\n","df_test_qa = df_test_qa.join(df_answers)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:47.574944Z","iopub.execute_input":"2023-02-09T09:25:47.575406Z","iopub.status.idle":"2023-02-09T09:25:50.945833Z","shell.execute_reply.started":"2023-02-09T09:25:47.575365Z","shell.execute_reply":"2023-02-09T09:25:50.944887Z"},"trusted":true,"id":"1yZVGVrxTxV9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that we have correctly created our train and test dataframes, we can inspect its data."],"metadata":{"id":"2DP6J40GTxV-"}},{"cell_type":"code","source":["df_test_qa"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:50.947172Z","iopub.execute_input":"2023-02-09T09:25:50.947643Z","iopub.status.idle":"2023-02-09T09:25:50.969887Z","shell.execute_reply.started":"2023-02-09T09:25:50.947607Z","shell.execute_reply":"2023-02-09T09:25:50.968878Z"},"trusted":true,"id":"zs0cZ7mxTxV-","outputId":"71b60888-f201-49d4-ff58-30b42e9367c5"},"execution_count":null,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"      story_id                                              story  \\\n0            0  Once upon a time, in a barn near a farm house,...   \n1            0  Once upon a time, in a barn near a farm house,...   \n2            0  Once upon a time, in a barn near a farm house,...   \n3            0  Once upon a time, in a barn near a farm house,...   \n4            0  Once upon a time, in a barn near a farm house,...   \n...        ...                                                ...   \n7978       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n7979       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n7980       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n7981       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n7982       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n\n                                           question  R1_start  R1_end  \\\n0                            What color was Cotton?        59      93   \n1                               Where did she live?        18      80   \n2                               Did she live alone?       196     215   \n3                            Who did she live with?       281     315   \n4                      What color were her sisters?       428     490   \n...                                             ...       ...     ...   \n7978  where does the nickname \"Sin City\" come from?      1037    1131   \n7979                          Which state is it in?       100     207   \n7980                     Is it located in a desert?       326     358   \n7981                what is the name of the desert?       345     359   \n7982                            is it a small city?       161     207   \n\n                                                     R1  y  \\\n0                    a little white kitten named Cotton  0   \n1     in a barn near a farm house, there lived a lit...  0   \n2                                   Cotton wasn't alone  1   \n3                    with her mommy and 5 other sisters  0   \n4     her sisters were all orange with beautiful whi...  0   \n...                                                 ... ..   \n7978  The city's tolerance for numerous forms of adu...  0   \n7979  Vegas, is the 28th-most populated city in the ...  0   \n7980                   within the greater Mojave Desert  1   \n7981                                     Mojave Desert.  0   \n7982     the most populated city in the state of Nevada  1   \n\n                                                 answer  \n0                                                 white  \n1                                             in a barn  \n2                                                    no  \n3                          with her mommy and 5 sisters  \n4                                      orange and white  \n...                                                 ...  \n7978  The city's tolerance for numerous forms of adu...  \n7979                                             Nevada  \n7980                                                Yes  \n7981                                     Mojave Desert.  \n7982                                                 No  \n\n[7918 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>story</th>\n      <th>question</th>\n      <th>R1_start</th>\n      <th>R1_end</th>\n      <th>R1</th>\n      <th>y</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Once upon a time, in a barn near a farm house,...</td>\n      <td>What color was Cotton?</td>\n      <td>59</td>\n      <td>93</td>\n      <td>a little white kitten named Cotton</td>\n      <td>0</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Once upon a time, in a barn near a farm house,...</td>\n      <td>Where did she live?</td>\n      <td>18</td>\n      <td>80</td>\n      <td>in a barn near a farm house, there lived a lit...</td>\n      <td>0</td>\n      <td>in a barn</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Once upon a time, in a barn near a farm house,...</td>\n      <td>Did she live alone?</td>\n      <td>196</td>\n      <td>215</td>\n      <td>Cotton wasn't alone</td>\n      <td>1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Once upon a time, in a barn near a farm house,...</td>\n      <td>Who did she live with?</td>\n      <td>281</td>\n      <td>315</td>\n      <td>with her mommy and 5 other sisters</td>\n      <td>0</td>\n      <td>with her mommy and 5 sisters</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Once upon a time, in a barn near a farm house,...</td>\n      <td>What color were her sisters?</td>\n      <td>428</td>\n      <td>490</td>\n      <td>her sisters were all orange with beautiful whi...</td>\n      <td>0</td>\n      <td>orange and white</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7978</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>where does the nickname \"Sin City\" come from?</td>\n      <td>1037</td>\n      <td>1131</td>\n      <td>The city's tolerance for numerous forms of adu...</td>\n      <td>0</td>\n      <td>The city's tolerance for numerous forms of adu...</td>\n    </tr>\n    <tr>\n      <th>7979</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>Which state is it in?</td>\n      <td>100</td>\n      <td>207</td>\n      <td>Vegas, is the 28th-most populated city in the ...</td>\n      <td>0</td>\n      <td>Nevada</td>\n    </tr>\n    <tr>\n      <th>7980</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>Is it located in a desert?</td>\n      <td>326</td>\n      <td>358</td>\n      <td>within the greater Mojave Desert</td>\n      <td>1</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>7981</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>what is the name of the desert?</td>\n      <td>345</td>\n      <td>359</td>\n      <td>Mojave Desert.</td>\n      <td>0</td>\n      <td>Mojave Desert.</td>\n    </tr>\n    <tr>\n      <th>7982</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>is it a small city?</td>\n      <td>161</td>\n      <td>207</td>\n      <td>the most populated city in the state of Nevada</td>\n      <td>1</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>7918 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["df_train_qa"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:50.972921Z","iopub.execute_input":"2023-02-09T09:25:50.973321Z","iopub.status.idle":"2023-02-09T09:25:50.991025Z","shell.execute_reply.started":"2023-02-09T09:25:50.973285Z","shell.execute_reply":"2023-02-09T09:25:50.990243Z"},"trusted":true,"id":"ufc_mhClTxV_","outputId":"0c844d2d-cc1f-427d-a2dc-92656fdea925"},"execution_count":null,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        story_id                                              story  \\\n0              0  The Vatican Apostolic Library (), more commonl...   \n1              0  The Vatican Apostolic Library (), more commonl...   \n2              0  The Vatican Apostolic Library (), more commonl...   \n3              0  The Vatican Apostolic Library (), more commonl...   \n4              0  The Vatican Apostolic Library (), more commonl...   \n...          ...                                                ...   \n108642      7198  (CNN) -- Cristiano Ronaldo provided the perfec...   \n108643      7198  (CNN) -- Cristiano Ronaldo provided the perfec...   \n108644      7198  (CNN) -- Cristiano Ronaldo provided the perfec...   \n108645      7198  (CNN) -- Cristiano Ronaldo provided the perfec...   \n108646      7198  (CNN) -- Cristiano Ronaldo provided the perfec...   \n\n                                 question  R1_start  R1_end  \\\n0       When was the Vat formally opened?       151     179   \n1                what is the library for?       454     494   \n2                      for what subjects?       457     511   \n3                                    and?       457     545   \n4               what was started in 2014?       769     879   \n...                                   ...       ...     ...   \n108642                     Who was a sub?      1405    1427   \n108643   Was it his first game this year?      1415    1467   \n108644  What position did the team reach?      1520    1555   \n108645             Who was ahead of them?      1557    1582   \n108646                       By how much?      1557    1581   \n\n                                                       R1  y  \\\n0                            Formally established in 1475  0   \n1                he Vatican Library is a research library  0   \n2       Vatican Library is a research library for hist...  0   \n3       Vatican Library is a research library for hist...  0   \n4       March 2014, the Vatican Library began an initi...  0   \n...                                                   ... ..   \n108642                             substitute Xabi Alonso  0   \n108643   Xabi Alonso made his first appearance of the ...  1   \n108644                Real moved up to third in the table  0   \n108645                          six points behind Barca.   0   \n108646                           six points behind Barca.  0   \n\n                                     answer  \n0       It was formally established in 1475  \n1                                  research  \n2                          history, and law  \n3          philosophy, science and theology  \n4                                a  project  \n...                                     ...  \n108642                          Xabi Alonso  \n108643                                  Yes  \n108644                                third  \n108645                               Barca.  \n108646                           six points  \n\n[107286 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>story</th>\n      <th>question</th>\n      <th>R1_start</th>\n      <th>R1_end</th>\n      <th>R1</th>\n      <th>y</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>When was the Vat formally opened?</td>\n      <td>151</td>\n      <td>179</td>\n      <td>Formally established in 1475</td>\n      <td>0</td>\n      <td>It was formally established in 1475</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>what is the library for?</td>\n      <td>454</td>\n      <td>494</td>\n      <td>he Vatican Library is a research library</td>\n      <td>0</td>\n      <td>research</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>for what subjects?</td>\n      <td>457</td>\n      <td>511</td>\n      <td>Vatican Library is a research library for hist...</td>\n      <td>0</td>\n      <td>history, and law</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>and?</td>\n      <td>457</td>\n      <td>545</td>\n      <td>Vatican Library is a research library for hist...</td>\n      <td>0</td>\n      <td>philosophy, science and theology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>what was started in 2014?</td>\n      <td>769</td>\n      <td>879</td>\n      <td>March 2014, the Vatican Library began an initi...</td>\n      <td>0</td>\n      <td>a  project</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108642</th>\n      <td>7198</td>\n      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n      <td>Who was a sub?</td>\n      <td>1405</td>\n      <td>1427</td>\n      <td>substitute Xabi Alonso</td>\n      <td>0</td>\n      <td>Xabi Alonso</td>\n    </tr>\n    <tr>\n      <th>108643</th>\n      <td>7198</td>\n      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n      <td>Was it his first game this year?</td>\n      <td>1415</td>\n      <td>1467</td>\n      <td>Xabi Alonso made his first appearance of the ...</td>\n      <td>1</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>108644</th>\n      <td>7198</td>\n      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n      <td>What position did the team reach?</td>\n      <td>1520</td>\n      <td>1555</td>\n      <td>Real moved up to third in the table</td>\n      <td>0</td>\n      <td>third</td>\n    </tr>\n    <tr>\n      <th>108645</th>\n      <td>7198</td>\n      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n      <td>Who was ahead of them?</td>\n      <td>1557</td>\n      <td>1582</td>\n      <td>six points behind Barca.</td>\n      <td>0</td>\n      <td>Barca.</td>\n    </tr>\n    <tr>\n      <th>108646</th>\n      <td>7198</td>\n      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n      <td>By how much?</td>\n      <td>1557</td>\n      <td>1581</td>\n      <td>six points behind Barca.</td>\n      <td>0</td>\n      <td>six points</td>\n    </tr>\n  </tbody>\n</table>\n<p>107286 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["print(\"Train Dataset\\n\\n---\\n\")\n","print(\"Dataset size: \\t\\t\\t\", df_train_qa.shape)\n","print(\"\\nDataset columns: \\t\\t\", df_train_qa.columns.values) "],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:50.993188Z","iopub.execute_input":"2023-02-09T09:25:50.993764Z","iopub.status.idle":"2023-02-09T09:25:50.999301Z","shell.execute_reply.started":"2023-02-09T09:25:50.993728Z","shell.execute_reply":"2023-02-09T09:25:50.998366Z"},"trusted":true,"id":"Xm24hi2oTxV_","outputId":"4d62023b-80b5-4db1-cd8b-a9e6d3a6fd4c"},"execution_count":null,"outputs":[{"name":"stdout","text":"Train Dataset\n\n---\n\nDataset size: \t\t\t (107286, 8)\n\nDataset columns: \t\t ['story_id' 'story' 'question' 'R1_start' 'R1_end' 'R1' 'y' 'answer']\n","output_type":"stream"}]},{"cell_type":"code","source":["df_train_qa.info()"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:51.000880Z","iopub.execute_input":"2023-02-09T09:25:51.001521Z","iopub.status.idle":"2023-02-09T09:25:51.051206Z","shell.execute_reply.started":"2023-02-09T09:25:51.001476Z","shell.execute_reply":"2023-02-09T09:25:51.050260Z"},"trusted":true,"id":"4YiPWVyfTxWA","outputId":"31026e26-318c-4cb2-f988-d93521d8427f"},"execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 107286 entries, 0 to 108646\nData columns (total 8 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   story_id  107286 non-null  int64 \n 1   story     107286 non-null  object\n 2   question  107286 non-null  object\n 3   R1_start  107286 non-null  int64 \n 4   R1_end    107286 non-null  int64 \n 5   R1        107286 non-null  object\n 6   y         107286 non-null  int64 \n 7   answer    107286 non-null  object\ndtypes: int64(4), object(4)\nmemory usage: 11.4+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":["df_train_qa.describe()"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:51.052490Z","iopub.execute_input":"2023-02-09T09:25:51.052810Z","iopub.status.idle":"2023-02-09T09:25:51.107575Z","shell.execute_reply.started":"2023-02-09T09:25:51.052778Z","shell.execute_reply":"2023-02-09T09:25:51.106508Z"},"trusted":true,"id":"XkgUbAx6TxWA","outputId":"5369aff7-285d-4219-d516-b50aa9dd687d"},"execution_count":null,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"            story_id       R1_start         R1_end              y\ncount  107286.000000  107286.000000  107286.000000  107286.000000\nmean     3615.448726     661.783336     715.118468       0.195021\nstd      2080.487032     486.726486     490.785795       0.396219\nmin         0.000000       0.000000       3.000000       0.000000\n25%      1808.250000     246.000000     297.000000       0.000000\n50%      3622.000000     596.000000     650.000000       0.000000\n75%      5423.000000    1012.000000    1069.000000       0.000000\nmax      7198.000000    6065.000000    6077.000000       1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>R1_start</th>\n      <th>R1_end</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>107286.000000</td>\n      <td>107286.000000</td>\n      <td>107286.000000</td>\n      <td>107286.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3615.448726</td>\n      <td>661.783336</td>\n      <td>715.118468</td>\n      <td>0.195021</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2080.487032</td>\n      <td>486.726486</td>\n      <td>490.785795</td>\n      <td>0.396219</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1808.250000</td>\n      <td>246.000000</td>\n      <td>297.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3622.000000</td>\n      <td>596.000000</td>\n      <td>650.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5423.000000</td>\n      <td>1012.000000</td>\n      <td>1069.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7198.000000</td>\n      <td>6065.000000</td>\n      <td>6077.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["num_yesno = df_train_qa[df_train_qa['y'] == 1].shape[0]\n","num_open = df_train_qa[df_train_qa['y'] == 0].shape[0]\n","num_questions = df_train_qa.shape[0]\n","\n","print(\"Total number of questions: \\t\", num_questions)\n","print(\"Number of yes-or-no questions: \\t\", num_yesno, \"(\", \"{:.2f}\".format((num_yesno*100)/num_questions), \"% )\")\n","print(\"Number of open questions: \\t\", num_open, \"(\", \"{:.2f}\".format((num_open*100)/num_questions), \"% )\\n\\n\")\n","\n","df_train_qa.groupby('y').size().plot(kind='pie',\n","                                       y = \"y\",\n","                                       label = \"Type\",\n","                                       autopct='%1.1f%%')"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:25:51.108872Z","iopub.execute_input":"2023-02-09T09:25:51.109615Z","iopub.status.idle":"2023-02-09T09:25:51.281634Z","shell.execute_reply.started":"2023-02-09T09:25:51.109575Z","shell.execute_reply":"2023-02-09T09:25:51.280201Z"},"trusted":true,"id":"Luiex6tjTxWB","outputId":"951a135b-52b9-4510-cf53-e4d6ddfbfa73"},"execution_count":null,"outputs":[{"name":"stdout","text":"Total number of questions: \t 107286\nNumber of yes-or-no questions: \t 20923 ( 19.50 % )\nNumber of open questions: \t 86363 ( 80.50 % )\n\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:ylabel='Type'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["We can see that our data is quite **imbalance**.\n","\n","As a rule of thumb, if a two-class dataset has a difference of greater than 65% to 35%, than it should be looked at as a dataset with class imbalance ([Machine Learning: How to Handle Class Imbalance](https://medium.com/analytics-vidhya/machine-learning-how-to-handle-class-imbalance-920e48c3e970)).\n","\n","Possible apprach:\n","\n","- Up-sample Minority Class (safer, but increase computational costs).\n","\n","- Down-sample Majority Class (quicker but we may loose information).\n","\n","At the moment, we will not perform any data manipulation to our dataframes."],"metadata":{"id":"Z6sm0cPuTxWC"}},{"cell_type":"markdown","source":["# Reference Model: T5\n","\n","As our first approach, we will utilize the [T5](https://arxiv.org/pdf/1910.10683.pdf) model to perform generative QA.\n","\n","T5 exploits the power of transfer learning (pre-train a model on a data-rich task before being fine-tuned on a downstream task) reaching, as the paper states, *state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more.*\n","\n","[Natural Language Inference](https://paperswithcode.com/sota/natural-language-inference-on-rte) latest performance.\n","\n","T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format.\n","\n","Being a Text Generation model (also known as causal language model), it is particularly suited for our answer generation problem. More precisely, these models are trained to learn the mapping between a pair of texts, in our case questions and answers."],"metadata":{"id":"3o80KgStTxWC"}},{"cell_type":"markdown","source":["Due to the limitation of our environment, we are going to take a subset of stories to perform training and validation."],"metadata":{"id":"ZD5SkyFSTxWD"}},{"cell_type":"code","source":["# Take a reduced portion of the dataframed to reuce computational costs\n","df_reduced_t5 = df_train_qa[df_train_qa['story_id'] <= 5000].copy()\n","\n","# Perform the split\n","df_train_t5, df_val_t5 = train_val_split(df_reduced_t5, 0.8, True)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:04:45.989105Z","iopub.execute_input":"2023-02-09T10:04:45.989482Z","iopub.status.idle":"2023-02-09T10:04:46.045403Z","shell.execute_reply.started":"2023-02-09T10:04:45.989450Z","shell.execute_reply":"2023-02-09T10:04:46.044438Z"},"trusted":true,"id":"8iXVq_SmTxWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Quick check for intersection\n","intersection = pd.merge(df_train_t5, df_val_t5, how='inner', on=['story_id'])\n","intersection.shape[0]"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:04:46.047592Z","iopub.execute_input":"2023-02-09T10:04:46.047976Z","iopub.status.idle":"2023-02-09T10:04:46.065169Z","shell.execute_reply.started":"2023-02-09T10:04:46.047940Z","shell.execute_reply":"2023-02-09T10:04:46.064113Z"},"trusted":true,"id":"xkOcTh_ATxWD","outputId":"b61a744c-4a2d-4952-a024-33dbcebdfe5a"},"execution_count":null,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":["hg_ds_t5 = convert_to_hg_dataset(['story_id', 'R1', 'R1_start', 'R1_end'], df_train_t5, df_val_t5)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:04:46.066707Z","iopub.execute_input":"2023-02-09T10:04:46.067067Z","iopub.status.idle":"2023-02-09T10:04:46.259046Z","shell.execute_reply.started":"2023-02-09T10:04:46.067032Z","shell.execute_reply":"2023-02-09T10:04:46.258075Z"},"trusted":true,"id":"8BHXBk2WTxWD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We decided to use [T5-small](https://huggingface.co/t5-small) which is a checkpoint of T5 with 60 million parameters. This was chosen in order to reduce space occupance and improving computational speed at the cost of a slightly worse performance. "],"metadata":{"id":"tLWsQHNmTxWE"}},{"cell_type":"code","source":["model_checkpoint_t5 = \"t5-small\""],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:04:46.261595Z","iopub.execute_input":"2023-02-09T10:04:46.262261Z","iopub.status.idle":"2023-02-09T10:04:46.267109Z","shell.execute_reply.started":"2023-02-09T10:04:46.262223Z","shell.execute_reply":"2023-02-09T10:04:46.266167Z"},"trusted":true,"id":"G-pXuXGlTxWE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now have to import the:\n","\n","- Tokenizer, to correctly perform preprocessing of our inputs.\n","- The model checkpoint.\n","\n","    The specific model checkpoint chosen was `TFT5ForConditionalGeneration` which is a T5 Model with a language modeling head on top (to predict what the next token is).\n","\n"],"metadata":{"id":"q-2Tu1UsTxWE"}},{"cell_type":"code","source":["tokenizer_t5 = AutoTokenizer.from_pretrained(model_checkpoint_t5)\n","model_t5 = TFT5ForConditionalGeneration.from_pretrained(model_checkpoint_t5)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:04:46.268806Z","iopub.execute_input":"2023-02-09T10:04:46.269509Z","iopub.status.idle":"2023-02-09T10:04:48.311814Z","shell.execute_reply.started":"2023-02-09T10:04:46.269471Z","shell.execute_reply":"2023-02-09T10:04:48.310807Z"},"trusted":true,"id":"FyRp9gqSTxWF","outputId":"c055e00b-b00e-48d8-f139-45e20f4fa091"},"execution_count":null,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n\nAll the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### Preprocessing\n","\n","To utilize the model, we first need to correctly preprocess our input sentences and convert them in a format the model expects, as well as generate the other inputs that the model requires.\n","\n","Mainly, the [tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer) performs:\n","\n","- Tokenizing (splitting strings in sub-word token strings), converting tokens strings to ids and back, and encoding/decoding (i.e., tokenizing and converting to integers).\n","\n","- Adding new tokens to the vocabulary.\n","\n","- Managing special tokens (like mask, beginning-of-sentence, etc.): adding them, assigning them to attributes in the tokenizer for easy access and making sure they are not split during tokenization.\n","\n","We also need to correctly format our text to the format in which our model was trained in order to maximize performance.\n","\n","As stated in the original T5 paper, since we are dealing with a QA task, we need to give to the model an input formatted as:\n","\n","- For the context-question part\n","\n","    question: TEXT context: TEXT\\</s>\n","    \n","- For the answer part\n","\n","    TEXT \\</s>\n","    "],"metadata":{"id":"IfaBfhYiTxWF"}},{"cell_type":"code","source":["max_target_length = 128\n","\n","def preprocess_function_t5(examples):\n","    # Correctly format the inputs\n","    inputs = 'question: %s  context: %s' % (examples['question'], examples['story'])\n","    model_inputs = tokenizer_t5(inputs, truncation=False)\n","\n","    # Setup the tokenizer for our \"target\", our answers\n","    with tokenizer_t5.as_target_tokenizer():\n","        labels = tokenizer_t5(\n","            examples[\"answer\"], max_length=max_target_length, truncation=False\n","        )\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:04:48.313677Z","iopub.execute_input":"2023-02-09T10:04:48.313944Z","iopub.status.idle":"2023-02-09T10:04:48.322517Z","shell.execute_reply.started":"2023-02-09T10:04:48.313918Z","shell.execute_reply":"2023-02-09T10:04:48.321496Z"},"trusted":true,"id":"enFkDFUGTxWF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets_t5 = hg_ds_t5.map(preprocess_function_t5, remove_columns=hg_ds_t5[\"train\"].column_names)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:04:48.324057Z","iopub.execute_input":"2023-02-09T10:04:48.324463Z","iopub.status.idle":"2023-02-09T10:06:55.070458Z","shell.execute_reply.started":"2023-02-09T10:04:48.324429Z","shell.execute_reply":"2023-02-09T10:06:55.069324Z"},"trusted":true,"colab":{"referenced_widgets":["7936a92d7c0a4c7abbabc33db2022d4b","00dd6057771b4705b26daddc0eaa984b"]},"id":"5f0tbmx7TxWF","outputId":"2622ef25-7064-4787-b22d-1d64f194ce0d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/59085 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7936a92d7c0a4c7abbabc33db2022d4b"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15007 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00dd6057771b4705b26daddc0eaa984b"}},"metadata":{}}]},{"cell_type":"code","source":["tokenized_datasets_t5"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:06:55.071879Z","iopub.execute_input":"2023-02-09T10:06:55.072497Z","iopub.status.idle":"2023-02-09T10:06:55.079551Z","shell.execute_reply.started":"2023-02-09T10:06:55.072458Z","shell.execute_reply":"2023-02-09T10:06:55.078390Z"},"trusted":true,"id":"MTTE0xHNTxWG","outputId":"a49527d7-79ae-4070-86bb-cf39ab8ddc1a"},"execution_count":null,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 59085\n    })\n    val: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 15007\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":["The resulting dataset dictionary contains the:\n","\n","- Training dataset.\n","- Validation dataset.\n","\n","Both of them have:\n","\n","- `input_ids` → Encoded input sentence.\n","- `attention_mask` → Indicates to the model which tokens should be attended to, and which should not (indicates the position of the padded indices).\n","- `labels` → Are the input_ids of the encoded target sequence.\n","\n","The model will automatically create the `decoder_input_ids` based on the `labels`.\n","\n","The padding will be later dealt with using a specific data collator."],"metadata":{"id":"QRe1H2oHTxWG"}},{"cell_type":"code","source":["print(tokenizer_t5.decode(tokenized_datasets_t5[\"train\"]['input_ids'][42]))\n","print(\"\\n\\n\",tokenizer_t5.decode(tokenized_datasets_t5[\"train\"]['labels'][42]))\n","\n","print(\"\\n\\n\",tokenized_datasets_t5[\"train\"]['input_ids'][42])\n","print(\"\\n\\n\",tokenized_datasets_t5[\"train\"]['labels'][42])"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:06:55.081001Z","iopub.execute_input":"2023-02-09T10:06:55.081457Z","iopub.status.idle":"2023-02-09T10:07:14.472816Z","shell.execute_reply.started":"2023-02-09T10:06:55.081415Z","shell.execute_reply":"2023-02-09T10:07:14.471727Z"},"trusted":true,"id":"A9_E9m1mTxWG","outputId":"75f08608-a7e2-43bb-a0ba-c677833a511b"},"execution_count":null,"outputs":[{"name":"stdout","text":"question: How much did they originally cost to produce? context: (CNN) -- The longest-running holiday special still has a very shiny nose. \"Rudolph the Red-Nosed Reindeer\" premiered on television December 6, 1964, and is now one of the holiday season's perennial favorites. The story of the reindeer who saves Christmas is beloved among children and adults alike. The Rankin-Bass animated film production company used Japanese puppets and stop motion to tell the tale, bolstered by a soundtrack featuring Burl Ives' rendition of the theme song. In the story, Santa's reindeer Donner and his wife have a son, Rudolph, who has the distinction of a nose that glows. He runs away after being made to feel an outcast and links up with an elf who dreams of becoming a dentist and an adventurer seeking silver and gold. After ending up on the Island of Misfit Toys and wandering for a while, Rudolph goes on to save his loved ones from the Abominable Snow Monster and guides Santa through a blizzard that threatens to ruin Christmas. In 2006, the New York Times reported that fans drove for miles to see the Rudolph and Santa Claus puppets at the Center for Puppetry Arts in Atlanta. The pair were thought to be the last of the surviving production puppets. They had been taken home by a production company employee and given to her children after filming was completed. \"In 2005, the nephew of the original rescuer found the puppets in a family attic and brought them to be appraised on the PBS series 'Antiques Roadshow,' \" the Times said. \"Created for about $5,000 each in 1964, they were valued at $8,000 to $10,000 for the pair. The family sold both figures to Kevin A. Kriess, the president of TimeandSpaceToys.com and a lifelong fan of the Rankin-Bass films.\"</s>\n\n\n about $5,000 each</s>\n\n\n [822, 10, 571, 231, 410, 79, 5330, 583, 12, 1759, 58, 2625, 10, 41, 254, 17235, 61, 1636, 37, 14783, 18, 24549, 2297, 534, 341, 65, 3, 9, 182, 18654, 8820, 5, 96, 17137, 26, 23589, 8, 1624, 18, 4168, 3843, 14317, 221, 49, 121, 13539, 26, 30, 4390, 1882, 8580, 18969, 6, 11, 19, 230, 80, 13, 8, 2297, 774, 31, 7, 24999, 13127, 5, 37, 733, 13, 8, 7101, 221, 49, 113, 1097, 7, 1619, 19, 11479, 859, 502, 11, 3513, 9391, 5, 37, 3, 22557, 77, 18, 14885, 7, 16822, 814, 999, 349, 261, 4318, 26141, 7, 11, 1190, 4644, 12, 817, 8, 5221, 6, 3, 25422, 15, 26, 57, 3, 9, 21183, 4767, 4152, 40, 27, 162, 7, 31, 30839, 13, 8, 3800, 2324, 5, 86, 8, 733, 6, 4625, 31, 7, 7101, 221, 49, 1008, 687, 11, 112, 2512, 43, 3, 9, 520, 6, 17806, 23589, 6, 113, 65, 8, 13005, 13, 3, 9, 8820, 24, 16507, 7, 5, 216, 3154, 550, 227, 271, 263, 12, 473, 46, 91, 5254, 11, 2416, 95, 28, 46, 3, 10386, 113, 6612, 13, 2852, 3, 9, 8370, 11, 46, 4472, 52, 3945, 4294, 11, 2045, 5, 621, 7784, 95, 30, 8, 2834, 13, 8306, 5616, 304, 63, 7, 11, 10735, 53, 21, 3, 9, 298, 6, 17806, 23589, 1550, 30, 12, 1097, 112, 1858, 2102, 45, 8, 891, 32, 1109, 179, 9394, 18117, 11, 9314, 4625, 190, 3, 9, 3, 7437, 5271, 986, 24, 20143, 7, 12, 13096, 1619, 5, 86, 3581, 6, 8, 368, 1060, 5324, 2196, 24, 2675, 10719, 21, 2286, 12, 217, 8, 17806, 23589, 11, 4625, 22021, 26141, 7, 44, 8, 1166, 21, 5004, 6811, 8224, 4218, 16, 9673, 5, 37, 3116, 130, 816, 12, 36, 8, 336, 13, 8, 3, 22279, 999, 26141, 7, 5, 328, 141, 118, 1026, 234, 57, 3, 9, 999, 349, 3490, 11, 787, 12, 160, 502, 227, 814, 53, 47, 2012, 5, 96, 1570, 3105, 6, 8, 23213, 13, 8, 926, 9635, 52, 435, 8, 26141, 7, 16, 3, 9, 384, 44, 1225, 11, 1940, 135, 12, 36, 29119, 26, 30, 8, 276, 4547, 939, 3, 31, 27355, 7771, 2409, 10049, 6, 31, 96, 8, 5324, 243, 5, 96, 254, 60, 920, 21, 81, 28176, 284, 16, 18969, 6, 79, 130, 12695, 44, 1514, 16235, 12, 24836, 21, 8, 3116, 5, 37, 384, 1916, 321, 5638, 12, 8595, 71, 5, 480, 2593, 7, 6, 8, 2753, 13, 2900, 232, 24722, 3696, 63, 7, 5, 287, 11, 3, 9, 280, 2961, 1819, 13, 8, 3, 22557, 77, 18, 14885, 7, 4852, 535, 1]\n\n\n [81, 28176, 284, 1]\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### Fine-tuning the model"],"metadata":{"id":"Q934M1nTTxWH"}},{"cell_type":"code","source":["# Training hyperparameters\n","\n","# Set random seed\n","seed = 42\n","set_random_seeds(seed=seed)\n","\n","# Hyperparams\n","learning_rate = 1e-4 #1e-4\n","num_train_epochs = 1\n","weight_decay = 0.01\n","batch_size = 8\n","\n","optimizer = AdamWeightDecay(learning_rate = learning_rate,\n","                            weight_decay_rate = weight_decay,)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:07:14.477308Z","iopub.execute_input":"2023-02-09T10:07:14.478166Z","iopub.status.idle":"2023-02-09T10:07:14.544214Z","shell.execute_reply.started":"2023-02-09T10:07:14.478124Z","shell.execute_reply":"2023-02-09T10:07:14.543085Z"},"trusted":true,"id":"f-rqlkY3TxWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we will use a data collator.\n","\n","[Data collator](https://huggingface.co/docs/transformers/main_classes/data_collator) are objects that will form a batch and perform padding if needed, by using a list of dataset elements as input.\n","\n","We utilized `DataCollatorForSeq2Seq` since is the one needed for our task (sequence-to-sequence (seq2seq) = Models that generate a new sequence from an input)"],"metadata":{"id":"r2yVKX4cTxWH"}},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer_t5, model=model_t5, return_tensors=\"np\")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:07:14.546272Z","iopub.execute_input":"2023-02-09T10:07:14.547082Z","iopub.status.idle":"2023-02-09T10:07:14.555461Z","shell.execute_reply.started":"2023-02-09T10:07:14.547044Z","shell.execute_reply":"2023-02-09T10:07:14.554531Z"},"trusted":true,"id":"hyoLDlN2TxWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next, we convert our datasets to `tf.data.Dataset`, which Keras understands natively. \n","\n","There are two ways to do this: we can use the slightly more low-level [`Dataset.to_tf_dataset()`](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.to_tf_dataset) method, or we can use [`Model.prepare_tf_dataset()`](https://huggingface.co/docs/transformers/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset).\n","\n","The main difference between these two is that the `Model` method can inspect the model to determine which column names it can use as input, which means you don't need to specify them yourself. "],"metadata":{"id":"bJlXP0rtTxWH"}},{"cell_type":"code","source":["train_set_t5 = model_t5.prepare_tf_dataset(\n","    tokenized_datasets_t5[\"train\"],\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=data_collator,\n",")\n","\n","val_set_t5 = model_t5.prepare_tf_dataset(\n","    tokenized_datasets_t5[\"val\"],\n","    batch_size=batch_size,\n","    shuffle=False,\n","    collate_fn=data_collator,\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:07:14.556796Z","iopub.execute_input":"2023-02-09T10:07:14.557205Z","iopub.status.idle":"2023-02-09T10:07:14.638189Z","shell.execute_reply.started":"2023-02-09T10:07:14.557169Z","shell.execute_reply":"2023-02-09T10:07:14.637389Z"},"trusted":true,"id":"UAM4vTfGTxWI","outputId":"0404fce5-f398-4ed2-acd3-888df2030f52"},"execution_count":null,"outputs":[{"name":"stderr","text":"You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"}]},{"cell_type":"markdown","source":["Now we can complie the model by just specifing the optimizer.\n","\n","The loss is automatically computed internally."],"metadata":{"id":"IraGg4CdTxWI"}},{"cell_type":"code","source":["# Compile the model\n","model_t5.compile(optimizer=optimizer)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:07:14.641004Z","iopub.execute_input":"2023-02-09T10:07:14.641261Z","iopub.status.idle":"2023-02-09T10:07:14.653863Z","shell.execute_reply.started":"2023-02-09T10:07:14.641236Z","shell.execute_reply":"2023-02-09T10:07:14.652679Z"},"trusted":true,"id":"re-xKjUhTxWI","outputId":"329505b4-e8cc-4d55-e138-5f3b62e29711"},"execution_count":null,"outputs":[{"name":"stderr","text":"No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n","output_type":"stream"}]},{"cell_type":"code","source":["# Train the model\n","model_t5.fit(\n","    x=train_set_t5,\n","    validation_data=val_set_t5,\n","    epochs=num_train_epochs\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:07:14.655008Z","iopub.execute_input":"2023-02-09T10:07:14.655259Z","iopub.status.idle":"2023-02-09T10:53:51.805894Z","shell.execute_reply.started":"2023-02-09T10:07:14.655236Z","shell.execute_reply":"2023-02-09T10:53:51.804850Z"},"trusted":true,"id":"yU5_XHZfTxWI","outputId":"e12747b9-53ac-4547-b0da-c0aa1193b507"},"execution_count":null,"outputs":[{"name":"stdout","text":"7385/7385 [==============================] - 2751s 370ms/step - loss: 1.2773 - val_loss: 1.0988\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f0895d7af90>"},"metadata":{}}]},{"cell_type":"markdown","source":["It was also tried to take a larger subset of our training dataset but, probably due to the size increase, the envirnoment ran out of memory."],"metadata":{"id":"lzhzMABlTxWI"}},{"cell_type":"markdown","source":["### Inference\n","\n","Let's see an example of answer."],"metadata":{"id":"VyWfKKZgTxWJ"}},{"cell_type":"code","source":["idx = 42\n","\n","# inputs = tokenizer([question], [context], return_tensors=\"np\")\n","input_text =  f\"question: {df_val_t5['question'][idx]} context: {df_val_t5['story'][idx]}\"\n","input_tokenized = tokenizer_t5(input_text, return_tensors='np', truncation=False)\n","\n","# input_tokenized = tokenizer(input_text, return_tensors=\"np\")\n","input_ids = input_tokenized.input_ids\n","attention_mask = input_tokenized.attention_mask\n","\n","# Generate the answer\n","model_answer = model_t5.generate(input_ids)\n","\n","print(\"Story: \\n\\n\", df_val_t5['story'][idx], \"\\n\\n\")\n","print(\"\\nQuestion: \", df_val_t5['question'][idx])\n","print(\"\\n\\nModel answer:  \\t\",tokenizer_t5.decode(model_answer[0], skip_special_tokens=True))\n","print(\"\\nReal answer: \\t\",df_val_t5['answer'][idx])"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T16:09:57.179670Z","iopub.execute_input":"2023-02-09T16:09:57.180008Z","iopub.status.idle":"2023-02-09T16:09:57.576465Z","shell.execute_reply.started":"2023-02-09T16:09:57.179978Z","shell.execute_reply":"2023-02-09T16:09:57.574694Z"},"trusted":true,"id":"5r47kpYUTxWJ","outputId":"fd08d408-8d23-414f-e813-acbc0b63d8a6"},"execution_count":null,"outputs":[{"name":"stdout","text":"Story: \n\n Local businessmen are increasingly facing competition from online retailers. Larry Pollock, owner of Camera Co/Op on South Congress, said he has been dealing with this kind of problem for years, even before the Internet. The struggle began with mail-order catalogues , which are similar to online retailers in that they have few employees to pay, no sales tax fees and no business venue to lease and manage. \n\n\"Their overhead is lower, but they don't offer a service like we do,\" Pollock said. \n\nPollock, however, said providing a valuable service to customers does not always guarantee continued sales. \n\n\"We spend 30 minutes to an hour with somebody and they go home and buy it on line,\" he said. \n\nAccording to the state comptroller's office, online shopping is developing at a more rapid rate than traditional businesses. \n\nIn spite of how fair or unfair online shopping may be to the local businessmen, consumers will continue to turn to the Internet for its variety and accessibility, said Mitch Wilson, an online shopper. \"You have a larger selection and it's easier to compare prices.\" \n\nWilson said he built his personal computer and paid a third of the price by shopping on line. \n\n\"Before the Internet, I would have had to go and buy an assembled computer from somebody like Dell,\" he said. \"Before I started shopping on line I could never find all the pieces I wanted. No single store had everything needed, so shopping on line saved me from having to buy from Dell.\" \n\nJanny Brazeal, a psychology freshman, said online shopping is too impersonal. \n\n\"'d rather see it in person, touch it, know that I'm getting it,\" she said. \n\nBrazeal also said she would not give out her credit card number or other personal information on line no matter how safe the site claims it is. \n\n\n\nQuestion:  who does it affect most?\n\n\nModel answer:  \t local businessmen\n\nReal answer: \t local businessmen\n","output_type":"stream"}]},{"cell_type":"markdown","source":["To evaluate the actual performances of our model, we will use the [SQuAD metric](https://huggingface.co/spaces/evaluate-metric/squad).\n","\n","\n","There are two dominant metrics used by many question answering datasets, including SQuAD: exact match (EM) and F1 score. These scores are computed on individual question+answer pairs."],"metadata":{"id":"zYpHyfdVTxWJ"}},{"cell_type":"code","source":["squad_metric = load(\"squad\")\n","\n","# Take a randome slice of our test set\n","n_samples = 1000\n","test_eval_subset = df_test_qa.sample(n = n_samples, random_state = seed).reset_index()\n","f1s = []\n","ems = []\n","\n","for idx in tqdm(range(n_samples)):\n","      \n","    input_text =  f\"question: {test_eval_subset['question'][idx]} context: {test_eval_subset['story'][idx]}\"\n","    inputs = tokenizer_t5(input_text, return_tensors='np', pad_to_max_length=True, truncation=True, max_length=1024)\n","    input_ids = inputs.input_ids\n","\n","    outputs = model_t5.generate(input_ids)\n","\n","    ref_text = test_eval_subset['answer'][idx]\n","    ref_start = test_eval_subset['R1_start'][idx]\n","\n","    # Extract this substring from the inputs\n","    answer = tokenizer_t5.decode(outputs[0], skip_special_tokens=True)\n","    \n","    predictions = [{'prediction_text': answer, 'id': '1'}]\n","    references = [{'answers': {'answer_start': [ref_start], 'text': [ref_text]}, 'id': '1'}]\n","    results = squad_metric.compute(predictions=predictions, references=references)\n","    f1s.append(results['f1'])\n","    ems.append(results['exact_match'])\n","\n","print(\"\\n\\nmean F1: \", np.mean(f1s))\n","print(\"\\n\\nmean EM: \", np.mean(ems))"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T15:25:53.740159Z","iopub.execute_input":"2023-02-09T15:25:53.740520Z","iopub.status.idle":"2023-02-09T15:33:07.765714Z","shell.execute_reply.started":"2023-02-09T15:25:53.740488Z","shell.execute_reply":"2023-02-09T15:33:07.764806Z"},"trusted":true,"id":"JddRcEGhTxWJ","outputId":"4ee8461f-7222-4f6d-a1ee-e4846680bc3e"},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [07:13<00:00,  2.31it/s]","output_type":"stream"},{"name":"stdout","text":"\n\nmean F1:  54.72581772847185\n\n\nmean EM:  43.9\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":["# Ensamble approach\n","\n","The main idea behind this approach was: \"Since generative QA is still a complex and training demanding task, what if we decomposed the problem into smaller tasks which can be managed by more specialized models\".\n","\n","At the moment we know we have to operate with:\n","\n","- A text passage which contains the information we want to extract to answer a question\n","- A list of questions and relative answers:\n","    - Yes-or-no questions\n","    - Open questions\n","\n","From this base, the chosen approach follows two path:\n","\n","1. Open question answering\n","\n","    An already established approach in QA is the [Extractive QA](https://www.pinecone.io/learn/question-answering/) which consists in teaching the model to find the span in the passage where the answer lies.\n","    \n","    Due to its widely use in QA, this represented a good starting point, but still it could be improved.\n","    \n","    Since Extractive QA can only extract span of text from the passage which include the answer, finding the context for yes-or-no questions proved to be a difficult task for the model and, since at the end we want to provide a sort of generative answer, we decided to let the extractive QA model only train on open questions.\n","    \n","    Having now, in theory, the correct span where the answer lies, we can provide these outputs as input into a similar T5 generative model as before.\n","    \n","    We will have to fine tune a new text-to-text T5 model, always for QA (since it performed the best), but now with a simpler task: paraphrasing a span, given its question, in order to generate an answer.\n","    \n","    The new T5 model will work as a mixture of summarization and paraphrasing, having the advantage of dealing with a smaller input text with respect to the previous T5 model.\n","    \n","2. Yes-or-No question answering\n","\n","    Having correctly defined a method to understand if a question is a yes-or-no QA (for instance using a Machine Learning approach), now we have to correctly address the [Boolean QA](https://arxiv.org/pdf/1905.10044.pdf) problem.\n","    \n","    This problem can be dealt as a classification task, teaching the model to classify an input as No (0) or Yes (1). The input will have the question and the relative context.\n","\n","![flow.png](data:image/png;base64,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)\n","    "],"metadata":{"id":"Lt_qEWEBTxWJ"}},{"cell_type":"markdown","source":["## Yes-or-No QA Classification\n","\n","In order to correctly pass the question to the correct branch of our ensamble, we first need a model that can divide open question from yes-or-no ones."],"metadata":{"id":"_9Xd1JnITxWK"}},{"cell_type":"markdown","source":["### Preprocessing and dataset manipulation"],"metadata":{"id":"HvDaoUw_TxWK"}},{"cell_type":"code","source":["# Copy the original dataframe\n","df_train_qa_classification = df_train_qa.copy()\n","\n","# Drop usless columns for classification\n","df_train_qa_classification = df_train_qa_classification.drop(['story_id', 'story', 'R1_start', 'R1_end', 'R1', 'answer'], axis=1)\n","\n","# Convert columns to lowercase\n","df_train_qa_classification['question'] = df_train_qa_classification['question'].apply(str.lower)\n","\n","df_train_qa_classification"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:54:42.910743Z","iopub.execute_input":"2023-02-09T10:54:42.911131Z","iopub.status.idle":"2023-02-09T10:54:42.961403Z","shell.execute_reply.started":"2023-02-09T10:54:42.911094Z","shell.execute_reply":"2023-02-09T10:54:42.960413Z"},"trusted":true,"id":"yFqRrE4DTxWK","outputId":"684bf95c-3bf9-4f8e-d8bb-5eec370bce44"},"execution_count":null,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"                                 question  y\n0       when was the vat formally opened?  0\n1                what is the library for?  0\n2                      for what subjects?  0\n3                                    and?  0\n4               what was started in 2014?  0\n...                                   ... ..\n108642                     who was a sub?  0\n108643   was it his first game this year?  1\n108644  what position did the team reach?  0\n108645             who was ahead of them?  0\n108646                       by how much?  0\n\n[107286 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>when was the vat formally opened?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>what is the library for?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>for what subjects?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>and?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>what was started in 2014?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108642</th>\n      <td>who was a sub?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108643</th>\n      <td>was it his first game this year?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108644</th>\n      <td>what position did the team reach?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108645</th>\n      <td>who was ahead of them?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108646</th>\n      <td>by how much?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>107286 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["# Copy the original test dataframe\n","df_test_qa_classification = df_test_qa.copy()"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:54:42.962957Z","iopub.execute_input":"2023-02-09T10:54:42.963320Z","iopub.status.idle":"2023-02-09T10:54:42.969569Z","shell.execute_reply.started":"2023-02-09T10:54:42.963284Z","shell.execute_reply":"2023-02-09T10:54:42.968411Z"},"trusted":true,"id":"jN05vEbmTxWK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We remember from our initial data analysis that yes-or-no question are quite less in number respect to open question, so we need to address this problem.\n","\n","In this notebook we decided to perform **upsampling**. "],"metadata":{"id":"5rfHR3c2TxWK"}},{"cell_type":"code","source":["# Get all the yes/no questions\n","yesno_questions = df_train_qa_classification[df_train_qa_classification[\"y\"] == 1]\n","open_questions = df_train_qa_classification[df_train_qa_classification[\"y\"] == 0]\n","\n","# Perform upsampling on the yes/no question\n","yesno_questions_upsample = resample(yesno_questions,\n","             replace=True,\n","             n_samples=int(num_open/1.8),\n","             random_state=42)\n","\n","# yesno_questions_downsample = resample(open_questions,\n","#              replace=True,\n","#              n_samples=int(num_open/1.5),\n","#              random_state=42)\n","\n","# Merge and create the new upsampled dataframe\n","df_train_qa_classification_upsample = pd.concat([df_train_qa_classification,yesno_questions_upsample])\n","\n","print(\"New total number of questions: \\t\", df_train_qa_classification_upsample.shape[0], \"\\n\")\n","print(\"New number of yes/no questions: \", df_train_qa_classification_upsample[df_train_qa_classification_upsample['y'] == 1].shape[0], \"\\n\")\n","print(\"New number of open questions: \\t\", df_train_qa_classification_upsample[df_train_qa_classification_upsample['y'] == 0].shape[0], \"\\n\")\n","\n","\n","df_train_qa_classification_upsample.groupby('y').size().plot(kind='pie',\n","                                       y = \"y\",\n","                                       label = \"Type\",\n","                                       autopct='%1.1f%%')"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:54:42.971881Z","iopub.execute_input":"2023-02-09T10:54:42.972827Z","iopub.status.idle":"2023-02-09T10:54:43.085981Z","shell.execute_reply.started":"2023-02-09T10:54:42.972789Z","shell.execute_reply":"2023-02-09T10:54:43.084570Z"},"trusted":true,"id":"l4oRG7tPTxWL","outputId":"9fbf95a4-5ee2-416a-9629-9d3684562a16"},"execution_count":null,"outputs":[{"name":"stdout","text":"New total number of questions: \t 155265 \n\nNew number of yes/no questions:  68902 \n\nNew number of open questions: \t 86363 \n\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:ylabel='Type'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### GridSearch to find best configuration\n","\n","The [find the best model](https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568#:~:text=Linear%20Support%20Vector%20Machine%20is,the%20best%20text%20classification%20algorithms.) we opted between:\n","\n","1. Naive bayes classifier\n","     \n","    Has the strong assumption of conditional indipendence between features, but we have some questions that are correlated.\n","\n","    1. **Complement Naive Bayes**\n","\n","        Particularly suited for imbalanced data sets\n","\n","        CNB regularly outperforms MNB (often by a considerable margin) on text classification tasks\t\n","\n","    2. **Multinomial Naive Bayes**\n","\n","        Variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). \n","\n","2. **Linear Support Vector Machine**\n","\n","  Linear Support Vector Machine is widely regarded as one of the best text classification algorithms\n","\n","At the end **Linear SVM** was chosen."],"metadata":{"id":"_MGYUsLuTxWL"}},{"cell_type":"code","source":["X = df_train_qa_classification_upsample['question']\n","y = df_train_qa_classification_upsample['y']\n","\n","svm = Pipeline([\n","    (\"pre\", TfidfVectorizer()),\n","    (\"svm\", SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None))\n","])\n","\n","parameters = {\n","    'pre__ngram_range': [(1, 1), (1, 2), (2,2)],\n","    'svm__max_iter': [5, 7],\n","    'svm__alpha': (1e-4, 1e-5)}\n","\n","gs_svm = GridSearchCV(svm, parameters, cv=5, n_jobs=-1)\n","\n","# svm = Pipeline([\n","#     (\"pre\", TfidfVectorizer(ngram_range= (1, 2))),\n","#     (\"svm\", SGDClassifier(loss='hinge', penalty='l2', alpha=1e-5, random_state=42, max_iter=7, tol=None))\n","# ])\n","\n","gs_svm.fit(X,y)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:54:43.091678Z","iopub.execute_input":"2023-02-09T10:54:43.092140Z","iopub.status.idle":"2023-02-09T10:56:20.904640Z","shell.execute_reply.started":"2023-02-09T10:54:43.092093Z","shell.execute_reply":"2023-02-09T10:56:20.903331Z"},"trusted":true,"id":"c5NE6_DOTxWL","outputId":"0f4592c5-c6c3-46ba-e15e-2854a8026527"},"execution_count":null,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('pre', TfidfVectorizer()),\n                                       ('svm',\n                                        SGDClassifier(alpha=0.001, max_iter=5,\n                                                      random_state=42,\n                                                      tol=None))]),\n             n_jobs=-1,\n             param_grid={'pre__ngram_range': [(1, 1), (1, 2), (2, 2)],\n                         'svm__alpha': (0.0001, 1e-05),\n                         'svm__max_iter': [5, 7]})"},"metadata":{}}]},{"cell_type":"code","source":["print(\"Best score reached: \",gs_svm.best_score_, \"\\n\")\n","\n","for param_name in sorted(parameters.keys()):\n","    print(\"%s: %r\" % (param_name, gs_svm.best_params_[param_name]))"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:56:20.906521Z","iopub.execute_input":"2023-02-09T10:56:20.906832Z","iopub.status.idle":"2023-02-09T10:56:20.915031Z","shell.execute_reply.started":"2023-02-09T10:56:20.906801Z","shell.execute_reply":"2023-02-09T10:56:20.913314Z"},"trusted":true,"id":"Xcix_lBBTxWL","outputId":"3453e39a-180e-41d3-b96e-31fae9ab410a"},"execution_count":null,"outputs":[{"name":"stdout","text":"Best score reached:  0.9795832930795736 \n\npre__ngram_range: (1, 2)\nsvm__alpha: 1e-05\nsvm__max_iter: 7\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### Evluate performance"],"metadata":{"id":"3uZS3J9VTxWL"}},{"cell_type":"code","source":["# Predict the categories of the test data\n","svm_pred = gs_svm.predict(df_test_qa_classification['question'])\n","\n","print(\"The svm accuracy is {}\".format(accuracy_score(df_test_qa_classification['y'], svm_pred)), \"\\n\")\n","\n","cm = confusion_matrix(df_test_qa_classification['y'], svm_pred)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot()\n","plt.show()\n","\n","print(\"\\n\", metrics.classification_report(df_test_qa_classification['y'], svm_pred, target_names=['open','yes_no']))"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T10:56:20.917992Z","iopub.execute_input":"2023-02-09T10:56:20.918736Z","iopub.status.idle":"2023-02-09T10:56:21.271025Z","shell.execute_reply.started":"2023-02-09T10:56:20.918697Z","shell.execute_reply":"2023-02-09T10:56:21.269738Z"},"trusted":true,"id":"HrlpIrmeTxWM","outputId":"be911b91-6b05-4f90-af9f-5a0016c72436"},"execution_count":null,"outputs":[{"name":"stdout","text":"The svm accuracy is 0.9705733771154332 \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"\n               precision    recall  f1-score   support\n\n        open       0.99      0.97      0.98      6305\n      yes_no       0.90      0.97      0.93      1613\n\n    accuracy                           0.97      7918\n   macro avg       0.94      0.97      0.96      7918\nweighted avg       0.97      0.97      0.97      7918\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":["## Extractive QA Model\n","\n","As before, due to computational limits, we take a subset of our training dataframe.\n","\n","We also remove all the yes-or-no question as stated before."],"metadata":{"id":"RzjpSsTzTxWM"}},{"cell_type":"code","source":["# Take a reduced portion of the dataframed to reuce computational costs\n","df_reduced_span = df_train_qa[df_train_qa['story_id'] <= 2300].copy()\n","\n","# Remove yes/no questions\n","df_reduced_spa = df_reduced_span.drop(df_reduced_span[df_reduced_span['y'] == 1].index)\n","\n","# Remove y column\n","df_reduced_span = df_reduced_span.drop(['y'], axis=1)\n","\n","# Perform the split\n","df_train_span, df_val_span = train_val_split(df_reduced_span, 0.8, True)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:25:48.787983Z","iopub.execute_input":"2023-02-09T12:25:48.788371Z","iopub.status.idle":"2023-02-09T12:25:48.823898Z","shell.execute_reply.started":"2023-02-09T12:25:48.788319Z","shell.execute_reply":"2023-02-09T12:25:48.822932Z"},"trusted":true,"id":"dIVSsONhTxWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Glance at the dataframe\n","df_train_span"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:25:50.725845Z","iopub.execute_input":"2023-02-09T12:25:50.726220Z","iopub.status.idle":"2023-02-09T12:25:50.745083Z","shell.execute_reply.started":"2023-02-09T12:25:50.726186Z","shell.execute_reply":"2023-02-09T12:25:50.743487Z"},"trusted":true,"id":"mc9QI3qETxWN","outputId":"6fc57466-cf7f-4380-8a8b-bf428979ae09"},"execution_count":null,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"       story_id                                              story  \\\n0             1  New York (CNN) -- More than 80 Michael Jackson...   \n1             1  New York (CNN) -- More than 80 Michael Jackson...   \n2             1  New York (CNN) -- More than 80 Michael Jackson...   \n3             1  New York (CNN) -- More than 80 Michael Jackson...   \n4             1  New York (CNN) -- More than 80 Michael Jackson...   \n...         ...                                                ...   \n27260      2299  (CNN) -- The suspect in the killing of Yale ph...   \n27261      2299  (CNN) -- The suspect in the killing of Yale ph...   \n27262      2299  (CNN) -- The suspect in the killing of Yale ph...   \n27263      2299  (CNN) -- The suspect in the killing of Yale ph...   \n27264      2299  (CNN) -- The suspect in the killing of Yale ph...   \n\n                                          question  R1_start  R1_end  \\\n0                      Where was the Auction held?       243     284   \n1                          How much did they make?       180     210   \n2                      How much did they expected?       292     342   \n3                        WHo buy the Jackson Glove      1295    1365   \n4           Where was the buyer of the glove from?      1331    1366   \n...                                            ...       ...     ...   \n27260            What does he maintain at his job?      1189    1238   \n27261         When is the memorial for the victim?      1440    1477   \n27262  What else is the school doing to honor her?      1479    1543   \n27263             What city is the defendant from?       644     675   \n27264                    What's his lawyer's name?       554     581   \n\n                                                      R1  \\\n0              Hard Rock Cafe in New York's Times Square   \n1                         reaping a total $2 million. \\n   \n2       pre-sale expectations of only $120,000 in sal...   \n3      Hoffman Ma, who bought the glove on behalf of ...   \n4                    behalf of Ponte 16 Resort in Macau,   \n...                                                  ...   \n27260  maintaining colonies for animals used in research   \n27261              memorial service for Le on October 12   \n27262  The university is also establishing a scholars...   \n27263                    Clark, of Branford, Connecticut   \n27264                        public defender Beth Merkin   \n\n                                                  answer  \n0                                         Hard Rock Cafe  \n1                                            $2 million.  \n2                                               $120,000  \n3                                             Hoffman Ma  \n4                                                  Macau  \n...                                                  ...  \n27260  maintaining colonies for animals used in resea...  \n27261    memorial service for Le on October 12, oct 12th  \n27262  The university is also establishing a scholars...  \n27263      Clark, of Branford, Connecticut , connecticut  \n27264           public defender Beth Merkin, beth merkin  \n\n[27265 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>story</th>\n      <th>question</th>\n      <th>R1_start</th>\n      <th>R1_end</th>\n      <th>R1</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n      <td>Where was the Auction held?</td>\n      <td>243</td>\n      <td>284</td>\n      <td>Hard Rock Cafe in New York's Times Square</td>\n      <td>Hard Rock Cafe</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n      <td>How much did they make?</td>\n      <td>180</td>\n      <td>210</td>\n      <td>reaping a total $2 million. \\n</td>\n      <td>$2 million.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n      <td>How much did they expected?</td>\n      <td>292</td>\n      <td>342</td>\n      <td>pre-sale expectations of only $120,000 in sal...</td>\n      <td>$120,000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n      <td>WHo buy the Jackson Glove</td>\n      <td>1295</td>\n      <td>1365</td>\n      <td>Hoffman Ma, who bought the glove on behalf of ...</td>\n      <td>Hoffman Ma</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n      <td>Where was the buyer of the glove from?</td>\n      <td>1331</td>\n      <td>1366</td>\n      <td>behalf of Ponte 16 Resort in Macau,</td>\n      <td>Macau</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27260</th>\n      <td>2299</td>\n      <td>(CNN) -- The suspect in the killing of Yale ph...</td>\n      <td>What does he maintain at his job?</td>\n      <td>1189</td>\n      <td>1238</td>\n      <td>maintaining colonies for animals used in research</td>\n      <td>maintaining colonies for animals used in resea...</td>\n    </tr>\n    <tr>\n      <th>27261</th>\n      <td>2299</td>\n      <td>(CNN) -- The suspect in the killing of Yale ph...</td>\n      <td>When is the memorial for the victim?</td>\n      <td>1440</td>\n      <td>1477</td>\n      <td>memorial service for Le on October 12</td>\n      <td>memorial service for Le on October 12, oct 12th</td>\n    </tr>\n    <tr>\n      <th>27262</th>\n      <td>2299</td>\n      <td>(CNN) -- The suspect in the killing of Yale ph...</td>\n      <td>What else is the school doing to honor her?</td>\n      <td>1479</td>\n      <td>1543</td>\n      <td>The university is also establishing a scholars...</td>\n      <td>The university is also establishing a scholars...</td>\n    </tr>\n    <tr>\n      <th>27263</th>\n      <td>2299</td>\n      <td>(CNN) -- The suspect in the killing of Yale ph...</td>\n      <td>What city is the defendant from?</td>\n      <td>644</td>\n      <td>675</td>\n      <td>Clark, of Branford, Connecticut</td>\n      <td>Clark, of Branford, Connecticut , connecticut</td>\n    </tr>\n    <tr>\n      <th>27264</th>\n      <td>2299</td>\n      <td>(CNN) -- The suspect in the killing of Yale ph...</td>\n      <td>What's his lawyer's name?</td>\n      <td>554</td>\n      <td>581</td>\n      <td>public defender Beth Merkin</td>\n      <td>public defender Beth Merkin, beth merkin</td>\n    </tr>\n  </tbody>\n</table>\n<p>27265 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["# Convert to hg dataset\n","hg_ds_span = convert_to_hg_dataset(['story_id', 'R1', 'answer'], df_train_span, df_val_span)\n","hg_ds_span"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:25:56.003055Z","iopub.execute_input":"2023-02-09T12:25:56.003857Z","iopub.status.idle":"2023-02-09T12:25:56.089377Z","shell.execute_reply.started":"2023-02-09T12:25:56.003819Z","shell.execute_reply":"2023-02-09T12:25:56.087084Z"},"trusted":true,"id":"PQCxnAm3TxWN","outputId":"af63d070-f398-4ce0-f7a9-0c6181ca5114"},"execution_count":null,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['story', 'question', 'R1_start', 'R1_end'],\n        num_rows: 27265\n    })\n    val: Dataset({\n        features: ['story', 'question', 'R1_start', 'R1_end'],\n        num_rows: 6792\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":["In this case, the `ALBERT` model was chosen, but it can be exchanged to any other model if wanted.\n","\n","For example, we also briefly tried also a lighter model such as `distillroberta` but it did not perform as good as `ALBERT`."],"metadata":{"id":"usNlo5skTxWO"}},{"cell_type":"code","source":["model_checkpoint_span = \"squirro/albert-base-v2-squad_v2\""],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:26:04.033400Z","iopub.execute_input":"2023-02-09T12:26:04.033754Z","iopub.status.idle":"2023-02-09T12:26:04.039120Z","shell.execute_reply.started":"2023-02-09T12:26:04.033724Z","shell.execute_reply":"2023-02-09T12:26:04.037911Z"},"trusted":true,"id":"8e04MNCwTxWP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import pretrained tokenizer and model for extractive QA\n","tokenizer_span = AutoTokenizer.from_pretrained(model_checkpoint_span)\n","model_span = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint_span)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:26:07.255374Z","iopub.execute_input":"2023-02-09T12:26:07.255743Z","iopub.status.idle":"2023-02-09T12:26:07.996750Z","shell.execute_reply.started":"2023-02-09T12:26:07.255712Z","shell.execute_reply":"2023-02-09T12:26:07.995738Z"},"trusted":true,"id":"g3b6CVb7TxWP","outputId":"2e07779c-b1bd-4844-f4ec-5e1b43206c1b"},"execution_count":null,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFAlbertForQuestionAnswering.\n\nAll the layers of TFAlbertForQuestionAnswering were initialized from the model checkpoint at squirro/albert-base-v2-squad_v2.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertForQuestionAnswering for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### Preprocessing\n","\n","Now, the most important part in Extractive QA is to correctly find the span, so correctly tokenize each input is essential.\n","\n","Usually, it is accettable to truncate long input sequence if they are longer than the maximum input length, but here, removing part of the the context might result in losing span where the answer lies.\n","\n","To deal with this, we allow long input sequence to be truncated and given as several input sequence.\n","\n","Also, in case the answer lies at the point we split the context, we allow some overlap between the features we generate controlled by the hyper-parameter `doc_stride`.\n"],"metadata":{"id":"hwPSpdh_TxWQ"}},{"cell_type":"code","source":["# The maximum length of a feature (question and context)\n","max_length = 384 \n","\n","# The overlap between two part of the context when splitting is performed.\n","doc_stride = 128  "],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T17:01:31.700703Z","iopub.execute_input":"2023-02-09T17:01:31.701049Z","iopub.status.idle":"2023-02-09T17:01:31.705212Z","shell.execute_reply.started":"2023-02-09T17:01:31.701019Z","shell.execute_reply":"2023-02-09T17:01:31.704298Z"},"trusted":true,"id":"JHSzoNMWTxWR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To correctly perofmed the tokenization, we implemented [this](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb#scrollTo=t0Fu_vte8XGz) tokenization function provided in a HuggingFace notebook,\n","\n","Essentialy:\n","- We allow our tokenize to truncate our input sequence, but we assure it truncates only the story and not the question by providing the `truncation=\"only_second\"` method.\n","- Next, we have to tell the tokenizer to keep the list of truncated featured by specifying `return_overflowing_tokens=True` and passing the `stride` we want to keep when keeping the overflowing part of the input sequence.\n","- Now we could have several lists of`input_ids` per input, so the problem now is to correctly find again the span of text where the answer lies. To perform this task we need to know the position of each feature, and this is done by specifying `return_offsets_mapping=True`. We will obtain the corresponding start and end character in the original text for each token in our input IDs."],"metadata":{"id":"HoZN6bYVTxWS"}},{"cell_type":"code","source":["idx = 210\n","\n","tokenized_example = tokenizer_span(\n","    hg_ds_span['train'][\"question\"][idx],\n","    hg_ds_span['train'][\"story\"][idx],\n","    max_length=max_length,\n","    truncation=\"only_second\",\n","    return_overflowing_tokens=True,\n","    return_offsets_mapping=True,\n","    stride=doc_stride,\n",")\n","\n","print(\"Example of tokenization:\\n\")\n","for x in tokenized_example[\"input_ids\"]:\n","    print(tokenizer_span.decode(x))\n","    \n","print(\"\\n\\nExample of offset mapping:\")\n","print(\"\\n\", tokenized_example[\"offset_mapping\"])"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T17:01:33.288766Z","iopub.execute_input":"2023-02-09T17:01:33.289314Z","iopub.status.idle":"2023-02-09T17:01:33.443985Z","shell.execute_reply.started":"2023-02-09T17:01:33.289273Z","shell.execute_reply":"2023-02-09T17:01:33.443073Z"},"trusted":true,"id":"lIg9i2VMTxWT","outputId":"7db589e9-56ac-40a0-d64b-bceafcfe777d"},"execution_count":null,"outputs":[{"name":"stdout","text":"Example of tokenization:\n\n[CLS] what is one of their hashtags?[SEP] a chinese actor's divorce from his wife, over her alleged extramarital affair, has social media buzzing, with posts about the subject gaining over five billion views. wang baoqiang announced online on sunday that he was divorcing his wife, ma rong, and sacking his agent, song zhe. he alleged that his marriage broke down after his wife had an affair with his agent, and that she had also transferred the couple's joint assets. ma has hit back at wang, accusing him of abandoning their family. the topic has sparked a debate about relationships and divorce. it seems wang's situation has struck a chord with many - which could explain the number of views, which are high even by chinese standards. the divorce quickly became a top trending topic in china. according to micro blog sina weibo, posts with the hashtag \"wang baoqiang divorce\" have been viewed over five billion times. chinese netizens seem to have rallied around wang, with topics like \"wang don't cry\" \"wang we support you\", quickly trending after news of the divorce spread. statistics by weibo showed that 47% of netizens' posts condemned ma for her affair, saying it had shattered her family. but why are they so interested? what is it about this one that's got all of china ruffled up? some people feel that this divorce seems to fit a certain trope - of a beautiful but ordinary girl marrying a rich but less good-looking man. it is not uncommon to hear the belief that a couple has to \"match\" at every level - be it in status, or physical appearance - for a relationship to work out. wang and ma's split has many people wondering if uneven matches are[SEP]\n[CLS] what is one of their hashtags?[SEP] netizens' posts condemned ma for her affair, saying it had shattered her family. but why are they so interested? what is it about this one that's got all of china ruffled up? some people feel that this divorce seems to fit a certain trope - of a beautiful but ordinary girl marrying a rich but less good-looking man. it is not uncommon to hear the belief that a couple has to \"match\" at every level - be it in status, or physical appearance - for a relationship to work out. wang and ma's split has many people wondering if uneven matches are unlikely to succeed. a lot of social media discussion has also centred around divorce, and in particular how people can protect themselves. wang has alleged that his wife transferred and hid some of the couple's assets. they're a wealthy couple - their assets, according to chinese media, include nine flats, a bmw car and various luxury goods. as a result, people are debating the importance of protecting individual assets, even after marriage.[SEP]\n\n\nExample of offset mapping:\n\n [[(0, 0), (0, 4), (5, 7), (8, 11), (12, 14), (15, 20), (21, 25), (25, 28), (28, 29), (29, 30), (0, 0), (0, 1), (2, 9), (10, 15), (15, 16), (16, 17), (18, 25), (26, 30), (31, 34), (35, 39), (39, 40), (41, 45), (46, 49), (50, 57), (58, 63), (63, 67), (67, 70), (71, 77), (77, 78), (79, 82), (83, 89), (90, 95), (96, 103), (103, 104), (105, 109), (110, 115), (116, 121), (122, 125), (126, 133), (134, 141), (142, 146), (147, 151), (152, 159), (160, 165), (165, 166), (169, 173), (174, 175), (174, 177), (177, 179), (179, 182), (183, 192), (193, 199), (200, 202), (203, 209), (210, 214), (215, 217), (218, 221), (222, 224), (224, 227), (227, 231), (232, 235), (236, 240), (240, 241), (242, 244), (245, 246), (245, 249), (249, 250), (251, 254), (255, 259), (259, 262), (263, 266), (267, 272), (272, 273), (274, 278), (279, 280), (280, 282), (282, 283), (284, 286), (287, 294), (295, 299), (300, 303), (304, 312), (313, 318), (319, 323), (324, 329), (330, 333), (334, 338), (339, 342), (343, 345), (346, 352), (353, 357), (358, 361), (362, 367), (367, 368), (369, 372), (373, 377), (378, 381), (382, 385), (386, 390), (391, 402), (403, 406), (407, 413), (413, 414), (414, 415), (416, 421), (422, 428), (428, 429), (430, 432), (433, 436), (437, 440), (441, 445), (446, 448), (449, 453), (453, 454), (455, 463), (464, 467), (468, 470), (471, 481), (482, 487), (488, 494), (494, 495), (498, 501), (502, 507), (508, 511), (512, 519), (520, 521), (522, 528), (529, 534), (535, 548), (549, 552), (553, 560), (560, 561), (562, 564), (565, 570), (571, 575), (575, 576), (576, 577), (578, 587), (588, 591), (592, 598), (599, 600), (601, 606), (607, 611), (612, 616), (617, 618), (617, 618), (619, 624), (625, 630), (631, 638), (639, 642), (643, 649), (650, 652), (653, 658), (658, 659), (660, 665), (666, 669), (670, 674), (675, 679), (680, 682), (683, 690), (691, 700), (700, 701), (704, 707), (708, 715), (716, 723), (724, 730), (731, 732), (733, 736), (737, 742), (742, 745), (746, 751), (752, 754), (755, 760), (760, 761), (762, 771), (772, 774), (775, 780), (781, 785), (786, 787), (786, 787), (787, 790), (791, 794), (794, 796), (796, 797), (798, 803), (804, 808), (809, 812), (813, 817), (817, 820), (821, 822), (821, 822), (822, 826), (827, 828), (827, 830), (830, 832), (832, 835), (836, 843), (843, 844), (845, 849), (850, 854), (855, 861), (862, 866), (867, 871), (872, 879), (880, 885), (885, 886), (887, 894), (895, 898), (898, 901), (901, 903), (904, 908), (909, 911), (912, 916), (917, 924), (925, 931), (932, 936), (936, 937), (938, 942), (943, 949), (950, 954), (955, 956), (955, 956), (956, 960), (961, 964), (964, 965), (965, 966), (967, 970), (970, 971), (972, 973), (972, 973), (973, 977), (978, 980), (981, 988), (989, 992), (992, 993), (993, 994), (995, 1002), (1003, 1008), (1008, 1011), (1012, 1017), (1018, 1022), (1023, 1025), (1026, 1029), (1030, 1037), (1038, 1044), (1044, 1045), (1046, 1056), (1057, 1059), (1060, 1063), (1063, 1065), (1066, 1072), (1073, 1077), (1078, 1079), (1078, 1081), (1082, 1084), (1085, 1088), (1088, 1091), (1091, 1093), (1093, 1094), (1095, 1100), (1101, 1110), (1111, 1113), (1114, 1117), (1118, 1121), (1122, 1128), (1128, 1129), (1130, 1136), (1137, 1139), (1140, 1143), (1144, 1153), (1154, 1157), (1158, 1164), (1164, 1165), (1168, 1171), (1172, 1175), (1176, 1179), (1180, 1184), (1185, 1187), (1188, 1198), (1198, 1199), (1200, 1204), (1205, 1207), (1208, 1210), (1211, 1216), (1217, 1221), (1222, 1225), (1226, 1230), (1230, 1231), (1231, 1232), (1233, 1236), (1237, 1240), (1241, 1243), (1244, 1249), (1250, 1251), (1250, 1254), (1254, 1257), (1258, 1260), (1260, 1261), (1264, 1268), (1269, 1275), (1276, 1280), (1281, 1285), (1286, 1290), (1291, 1298), (1299, 1304), (1305, 1307), (1308, 1311), (1312, 1313), (1314, 1321), (1322, 1323), (1322, 1326), (1326, 1327), (1328, 1329), (1328, 1329), (1330, 1332), (1333, 1334), (1335, 1344), (1345, 1348), (1349, 1357), (1358, 1362), (1363, 1371), (1372, 1373), (1374, 1378), (1379, 1382), (1383, 1387), (1388, 1392), (1392, 1393), (1393, 1400), (1401, 1404), (1404, 1405), (1406, 1408), (1409, 1411), (1412, 1415), (1416, 1424), (1425, 1427), (1428, 1432), (1433, 1436), (1437, 1443), (1444, 1448), (1449, 1450), (1451, 1457), (1458, 1461), (1462, 1464), (1465, 1466), (1465, 1466), (1466, 1471), (1471, 1472), (1473, 1475), (1476, 1481), (1482, 1487), (1488, 1489), (1488, 1489), (1490, 1492), (1493, 1495), (1496, 1498), (1499, 1505), (1505, 1506), (1507, 1509), (1510, 1518), (1519, 1529), (1530, 1531), (1530, 1531), (1532, 1535), (1536, 1537), (1538, 1550), (1551, 1553), (1554, 1558), (1559, 1562), (1562, 1563), (1564, 1568), (1569, 1572), (1573, 1575), (1575, 1576), (1576, 1577), (1578, 1583), (1584, 1587), (1588, 1592), (1593, 1599), (1600, 1609), (1610, 1612), (1613, 1619), (1620, 1627), (1628, 1631), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 11), (12, 14), (15, 20), (21, 25), (25, 28), (28, 29), (29, 30), (0, 0), (1085, 1088), (1088, 1091), (1091, 1093), (1093, 1094), (1095, 1100), (1101, 1110), (1111, 1113), (1114, 1117), (1118, 1121), (1122, 1128), (1128, 1129), (1130, 1136), (1137, 1139), (1140, 1143), (1144, 1153), (1154, 1157), (1158, 1164), (1164, 1165), (1168, 1171), (1172, 1175), (1176, 1179), (1180, 1184), (1185, 1187), (1188, 1198), (1198, 1199), (1200, 1204), (1205, 1207), (1208, 1210), (1211, 1216), (1217, 1221), (1222, 1225), (1226, 1230), (1230, 1231), (1231, 1232), (1233, 1236), (1237, 1240), (1241, 1243), (1244, 1249), (1250, 1251), (1250, 1254), (1254, 1257), (1258, 1260), (1260, 1261), (1264, 1268), (1269, 1275), (1276, 1280), (1281, 1285), (1286, 1290), (1291, 1298), (1299, 1304), (1305, 1307), (1308, 1311), (1312, 1313), (1314, 1321), (1322, 1323), (1322, 1326), (1326, 1327), (1328, 1329), (1328, 1329), (1330, 1332), (1333, 1334), (1335, 1344), (1345, 1348), (1349, 1357), (1358, 1362), (1363, 1371), (1372, 1373), (1374, 1378), (1379, 1382), (1383, 1387), (1388, 1392), (1392, 1393), (1393, 1400), (1401, 1404), (1404, 1405), (1406, 1408), (1409, 1411), (1412, 1415), (1416, 1424), (1425, 1427), (1428, 1432), (1433, 1436), (1437, 1443), (1444, 1448), (1449, 1450), (1451, 1457), (1458, 1461), (1462, 1464), (1465, 1466), (1465, 1466), (1466, 1471), (1471, 1472), (1473, 1475), (1476, 1481), (1482, 1487), (1488, 1489), (1488, 1489), (1490, 1492), (1493, 1495), (1496, 1498), (1499, 1505), (1505, 1506), (1507, 1509), (1510, 1518), (1519, 1529), (1530, 1531), (1530, 1531), (1532, 1535), (1536, 1537), (1538, 1550), (1551, 1553), (1554, 1558), (1559, 1562), (1562, 1563), (1564, 1568), (1569, 1572), (1573, 1575), (1575, 1576), (1576, 1577), (1578, 1583), (1584, 1587), (1588, 1592), (1593, 1599), (1600, 1609), (1610, 1612), (1613, 1619), (1620, 1627), (1628, 1631), (1632, 1640), (1641, 1643), (1644, 1651), (1651, 1652), (1655, 1656), (1657, 1660), (1661, 1663), (1664, 1670), (1671, 1676), (1677, 1687), (1688, 1691), (1692, 1696), (1697, 1703), (1703, 1704), (1705, 1711), (1712, 1719), (1719, 1720), (1721, 1724), (1725, 1727), (1728, 1738), (1739, 1742), (1743, 1749), (1750, 1753), (1754, 1761), (1762, 1772), (1772, 1773), (1774, 1778), (1779, 1782), (1783, 1790), (1791, 1795), (1796, 1799), (1800, 1804), (1805, 1816), (1817, 1820), (1821, 1824), (1825, 1829), (1830, 1832), (1833, 1836), (1837, 1843), (1843, 1844), (1844, 1845), (1846, 1852), (1852, 1853), (1854, 1858), (1858, 1859), (1859, 1861), (1862, 1863), (1864, 1871), (1872, 1878), (1879, 1880), (1879, 1880), (1881, 1886), (1887, 1893), (1893, 1894), (1895, 1904), (1905, 1907), (1908, 1915), (1916, 1921), (1921, 1922), (1923, 1930), (1931, 1935), (1936, 1940), (1940, 1941), (1941, 1942), (1943, 1944), (1945, 1948), (1949, 1952), (1953, 1956), (1957, 1964), (1965, 1971), (1972, 1977), (1977, 1978), (1979, 1981), (1982, 1983), (1984, 1990), (1990, 1991), (1992, 1998), (1999, 2002), (2003, 2011), (2012, 2015), (2016, 2026), (2027, 2029), (2030, 2040), (2041, 2051), (2052, 2058), (2058, 2059), (2060, 2064), (2065, 2070), (2071, 2079), (2079, 2080), (0, 0)]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":["- We need to distinguish the question and context part of the input, and this is performed using the `sequence_ids()` method, which will return a sequence of form `[None, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, None]` where: `None` are for special tokens, `0` for tokens corresponding to words in the first sequence and `1` for tokens corresponding to words in the second sequence."],"metadata":{"id":"r_dekDj6TxWT"}},{"cell_type":"code","source":["sequence_ids = tokenized_example.sequence_ids()\n","print(sequence_ids)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T17:01:56.440760Z","iopub.execute_input":"2023-02-09T17:01:56.441125Z","iopub.status.idle":"2023-02-09T17:01:56.446886Z","shell.execute_reply.started":"2023-02-09T17:01:56.441093Z","shell.execute_reply":"2023-02-09T17:01:56.445892Z"},"trusted":true,"id":"f9KpN3dUTxWU","outputId":"46b3a695-0e71-4133-cf5b-21b4b77957ae"},"execution_count":null,"outputs":[{"name":"stdout","text":"[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n","output_type":"stream"}]},{"cell_type":"markdown","source":["- Now with everything, we can find the first and last token of the answer in one of our input feature (or if the answer is not in this feature)"],"metadata":{"id":"kqqxbFYxTxWU"}},{"cell_type":"code","source":["start_char = hg_ds_span['train'][\"R1_start\"][idx]\n","end_char = hg_ds_span['train'][\"R1_end\"][idx]\n","\n","print(\"Original start: \", start_char)\n","print(\"Original end: \", end_char)\n","\n","# Start token index of the current span in the text.\n","token_start_index = 0\n","while sequence_ids[token_start_index] != 1:\n","    token_start_index += 1\n","    \n","print(\"\\nStart token index of the current span: \", token_start_index)\n","\n","# End token index of the current span in the text.\n","token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n","while sequence_ids[token_end_index] != 1:\n","    token_end_index -= 1\n","    \n","print(\"End token index of the current span: \", token_end_index, \"\\n\")\n","\n","# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n","offsets = tokenized_example[\"offset_mapping\"][0]\n","print(\"Start token index of whole mapping: \", offsets[token_start_index][0])\n","print(\"End token index of whole mapping: \", offsets[token_end_index][1])\n","if (\n","    offsets[token_start_index][0] <= start_char\n","    and offsets[token_end_index][1] >= end_char\n","):\n","    # Move the token_start_index and token_end_index to the two ends of the answer.\n","    while (\n","        token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char\n","    ):\n","        token_start_index += 1\n","    start_position = token_start_index - 1\n","    while offsets[token_end_index][1] >= end_char:\n","        token_end_index -= 1\n","    end_position = token_end_index + 1\n","    print(\"\\nNew start-end positions: \", start_position, end_position)\n","else:\n","    print(\"The answer is not in this feature.\")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T17:02:00.159316Z","iopub.execute_input":"2023-02-09T17:02:00.159718Z","iopub.status.idle":"2023-02-09T17:02:00.191772Z","shell.execute_reply.started":"2023-02-09T17:02:00.159686Z","shell.execute_reply":"2023-02-09T17:02:00.190278Z"},"trusted":true,"id":"Wm1IWX1XTxWU","outputId":"97065d37-57cd-45af-c47a-50667f03ee08"},"execution_count":null,"outputs":[{"name":"stdout","text":"Original start:  822\nOriginal end:  843\n\nStart token index of the current span:  11\nEnd token index of the current span:  382 \n\nStart token index of whole mapping:  0\nEnd token index of whole mapping:  1631\n\nNew start-end positions:  191 196\n","output_type":"stream"}]},{"cell_type":"code","source":["print(\"Re-aligned start-end tokens:\\n\",\n","    tokenizer_span.decode(\n","        tokenized_example[\"input_ids\"][0][start_position : end_position + 1]\n","    )\n",")\n","print(\"\\nOriginal answer span:\\n\",hg_ds_span['train'][\"story\"][idx][hg_ds_span['train'][\"R1_start\"][idx] : hg_ds_span['train'][\"R1_end\"][idx]])"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T17:03:54.898962Z","iopub.execute_input":"2023-02-09T17:03:54.899316Z","iopub.status.idle":"2023-02-09T17:03:54.974844Z","shell.execute_reply.started":"2023-02-09T17:03:54.899284Z","shell.execute_reply":"2023-02-09T17:03:54.973658Z"},"trusted":true,"id":"uBxfW7RoTxWV","outputId":"a17eed21-6774-433f-c282-2adf058c1dcd"},"execution_count":null,"outputs":[{"name":"stdout","text":"Re-aligned start-end tokens:\n wang baoqiang divorce\n\nOriginal answer span:\n Wang BaoQiang Divorce\n","output_type":"stream"}]},{"cell_type":"markdown","source":["Finally, we can combine everything explained before and create a preprocess function which will correctly preprocess batches of our inputs."],"metadata":{"id":"BCpAc6FUTxWV"}},{"cell_type":"code","source":["def preprocess_function_span(examples):\n","    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n","    # in one example possible giving several features when a context is long, each of those features having a\n","    # context that overlaps a bit the context of the previous feature.\n","    tokenized_examples = tokenizer_span(\n","        examples[\"question\"],\n","        examples[\"story\"],\n","        truncation=\"only_second\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    # Since one example might give us several features if it has a long context, we need a map from a feature to\n","    # its corresponding example. This key gives us just that.\n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","    # The offset mappings will give us a map from token to character position in the original context. This will\n","    # help us compute the start_positions and end_positions.\n","    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n","\n","    # Let's label those examples!\n","    tokenized_examples[\"start_positions\"] = []\n","    tokenized_examples[\"end_positions\"] = []\n","\n","\n","    for i, offsets in enumerate(offset_mapping):\n","        # We will label impossible answers with the index of the CLS token.\n","        input_ids = tokenized_examples[\"input_ids\"][i]\n","        cls_index = input_ids.index(tokenizer_span.cls_token_id)\n","\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","\n","        # If no answers are given, set the cls_index as answer.\n","        if  examples['R1_start'] == 0:\n","            tokenized_examples[\"start_positions\"].append(cls_index)\n","            tokenized_examples[\"end_positions\"].append(cls_index)\n","        else:\n","            # Start/end character index of the answer in the text.\n","            start_char = examples['R1_start'][sample_index]\n","            end_char = examples['R1_end'][sample_index]\n","\n","            # Start token index of the current span in the text.\n","            token_start_index = 0\n","            while sequence_ids[token_start_index] != 1:\n","                token_start_index += 1\n","\n","            # End token index of the current span in the text.\n","            token_end_index = len(input_ids) - 1\n","            while sequence_ids[token_end_index] != 1:\n","                token_end_index -= 1\n","\n","            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n","            if not (\n","                offsets[token_start_index][0] <= start_char\n","                and offsets[token_end_index][1] >= end_char\n","            ):\n","                tokenized_examples[\"start_positions\"].append(cls_index)\n","                tokenized_examples[\"end_positions\"].append(cls_index)\n","            else:\n","                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n","                # Note: we could go after the last offset if the answer is the last word (edge case).\n","                while (\n","                    token_start_index < len(offsets)\n","                    and offsets[token_start_index][0] <= start_char\n","                ):\n","                    token_start_index += 1\n","                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n","\n","    return tokenized_examples"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:28:07.328383Z","iopub.execute_input":"2023-02-09T12:28:07.328757Z","iopub.status.idle":"2023-02-09T12:28:07.341502Z","shell.execute_reply.started":"2023-02-09T12:28:07.328726Z","shell.execute_reply":"2023-02-09T12:28:07.340385Z"},"trusted":true,"id":"y1lM7G3FTxWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess our train and val datasets\n","tokenized_datasets_span = hg_ds_span.map(\n","    preprocess_function_span, batched=True, remove_columns=hg_ds_span[\"train\"].column_names\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:28:09.694510Z","iopub.execute_input":"2023-02-09T12:28:09.694870Z","iopub.status.idle":"2023-02-09T12:28:59.410339Z","shell.execute_reply.started":"2023-02-09T12:28:09.694839Z","shell.execute_reply":"2023-02-09T12:28:59.409308Z"},"trusted":true,"colab":{"referenced_widgets":["3cc6b0fafca54527901204f065fcfe42","fbfa5656930747be8d8955efa5fd47db"]},"id":"8ydOJl-KTxWX","outputId":"573f624d-d934-4c3f-c32a-b89d036e739c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc6b0fafca54527901204f065fcfe42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbfa5656930747be8d8955efa5fd47db"}},"metadata":{}}]},{"cell_type":"code","source":["tokenized_datasets_span"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:28:59.412571Z","iopub.execute_input":"2023-02-09T12:28:59.413654Z","iopub.status.idle":"2023-02-09T12:28:59.420609Z","shell.execute_reply.started":"2023-02-09T12:28:59.413613Z","shell.execute_reply":"2023-02-09T12:28:59.419510Z"},"trusted":true,"id":"d60r-noCTxWX","outputId":"7508baec-0c1e-4c96-a5c5-20c55dcbacdf"},"execution_count":null,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 28189\n    })\n    val: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 7124\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":["### Fine-tuning the model"],"metadata":{"id":"Fhq2r9d5TxWX"}},{"cell_type":"code","source":["# Training hyperparameters\n","\n","learning_rate = 5e-5 #[2,5]e-5\n","num_train_epochs = 1\n","weight_decay = 0.001\n","batch_size = 16\n","\n","# Optimizer\n","optimizer = AdamWeightDecay(learning_rate=learning_rate,\n","                            weight_decay_rate=weight_decay,)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:30:07.330864Z","iopub.execute_input":"2023-02-09T12:30:07.331211Z","iopub.status.idle":"2023-02-09T12:30:07.336529Z","shell.execute_reply.started":"2023-02-09T12:30:07.331181Z","shell.execute_reply":"2023-02-09T12:30:07.335500Z"},"trusted":true,"id":"cyUhwMMWTxWY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now convert our dataset to `tf.data.Dataset` as we arleady done before, and this time we will use the default `DataCollator` since our input sequence are already padded to the same length and ready to be dealt with."],"metadata":{"id":"jqhzDVisTxWY"}},{"cell_type":"code","source":["train_set_span = model_span.prepare_tf_dataset(\n","    tokenized_datasets_span[\"train\"],\n","    shuffle=True,\n","    batch_size=batch_size\n",")\n","\n","validation_set_span = model_span.prepare_tf_dataset(\n","    tokenized_datasets_span[\"val\"],\n","    shuffle=False,\n","    batch_size=batch_size\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:30:08.920000Z","iopub.execute_input":"2023-02-09T12:30:08.920373Z","iopub.status.idle":"2023-02-09T12:30:09.015146Z","shell.execute_reply.started":"2023-02-09T12:30:08.920323Z","shell.execute_reply":"2023-02-09T12:30:09.013968Z"},"trusted":true,"id":"kzsITP4fTxWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model_span.compile(optimizer=optimizer)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:30:10.020869Z","iopub.execute_input":"2023-02-09T12:30:10.021806Z","iopub.status.idle":"2023-02-09T12:30:10.036434Z","shell.execute_reply.started":"2023-02-09T12:30:10.021756Z","shell.execute_reply":"2023-02-09T12:30:10.035537Z"},"trusted":true,"id":"6gdLDmTITxWZ","outputId":"4e85dd01-1b35-4ff0-db41-95b0f3ad8015"},"execution_count":null,"outputs":[{"name":"stderr","text":"No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n","output_type":"stream"}]},{"cell_type":"code","source":["model_span.fit(\n","    train_set_span,\n","    validation_data=validation_set_span,\n","    epochs=num_train_epochs\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T12:30:11.874487Z","iopub.execute_input":"2023-02-09T12:30:11.874851Z","iopub.status.idle":"2023-02-09T13:29:45.724864Z","shell.execute_reply.started":"2023-02-09T12:30:11.874819Z","shell.execute_reply":"2023-02-09T13:29:45.723588Z"},"trusted":true,"id":"NAvnYS0pTxWZ","outputId":"0fd5bce0-811f-4006-a798-ac21ecddaf7b"},"execution_count":null,"outputs":[{"name":"stdout","text":"1761/1761 [==============================] - 3546s 2s/step - loss: 2.8990 - val_loss: 2.8192\n","output_type":"stream"},{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f043efa14d0>"},"metadata":{}}]},{"cell_type":"markdown","source":["### Inference"],"metadata":{"id":"k00oZn_6TxWZ"}},{"cell_type":"code","source":["idx = 220\n","\n","# inputs = tokenizer([question], [context], return_tensors=\"np\")\n","inputs = tokenizer_span([df_val_span['question'][idx]], [df_val_span['story'][idx]], return_tensors=\"np\")\n","\n","outputs = model_span(inputs)\n","\n","start_position = np.argmax(outputs.start_logits[0])\n","end_position = np.argmax(outputs.end_logits[0])\n","\n","# Extract this substring from the inputs\n","answer = inputs[\"input_ids\"][0, start_position:end_position + 1]\n","\n","print(\"\\nQuestion: \", df_val_span['question'][idx], \"\\n\\n\")\n","print(\"Model answer:  \\t\",tokenizer_span.decode(answer))\n","print(\"\\nR1: \\t\\t\", df_val_span['R1'][idx])\n","print(\"\\nReal answer: \\t\",df_val_span['answer'][idx])"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:30:53.080114Z","iopub.execute_input":"2023-02-09T13:30:53.080492Z","iopub.status.idle":"2023-02-09T13:30:53.222321Z","shell.execute_reply.started":"2023-02-09T13:30:53.080462Z","shell.execute_reply":"2023-02-09T13:30:53.221182Z"},"trusted":true,"id":"pN50ZU0ATxWZ","outputId":"b4032795-ce16-4284-ead1-5ec399542b0d"},"execution_count":null,"outputs":[{"name":"stdout","text":"\nQuestion:  When was the city formed? \n\n\nModel answer:  \t the city was incorporated in 1852\n\nR1: \t\t n 1852. \n\nReal answer: \t In 1852\n","output_type":"stream"}]},{"cell_type":"code","source":["n_samples = 2000\n","test_eval_subset = df_test_qa.sample(n = n_samples, random_state = seed).reset_index()\n","f1s = []\n","ems = []\n","\n","for idx in tqdm(range(n_samples)):\n","\n","    inputs = tokenizer_span([test_eval_subset['question'][idx]], [test_eval_subset['story'][idx]], return_tensors=\"np\", truncation=\"only_second\", max_length=max_length,)\n","\n","    outputs = model_span(inputs)\n","\n","    ref_text = test_eval_subset['R1'][idx]\n","    ref_start = test_eval_subset['R1_start'][idx]\n","\n","    start_position = np.argmax(outputs.start_logits[0])\n","    end_position = np.argmax(outputs.end_logits[0])\n","\n","    # Extract this substring from the inputs\n","    answer = inputs[\"input_ids\"][0, start_position:end_position + 1]\n","    answer = tokenizer_span.decode(answer)\n","\n","    predictions = [{'prediction_text': answer, 'id': '1'}]\n","    references = [{'answers': {'answer_start': [ref_start], 'text': [ref_text]}, 'id': '1'}]\n","    results = squad_metric.compute(predictions=predictions, references=references)\n","    f1s.append(results['f1'])\n","    ems.append(results['exact_match'])\n","\n","print(\"\\n\\nmean F1: \", np.mean(f1s))\n","print(\"\\n\\nmean EM: \", np.mean(ems))"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:30:59.413310Z","iopub.execute_input":"2023-02-09T13:30:59.413786Z","iopub.status.idle":"2023-02-09T13:35:19.280703Z","shell.execute_reply.started":"2023-02-09T13:30:59.413743Z","shell.execute_reply":"2023-02-09T13:35:19.279658Z"},"trusted":true,"id":"QSbu1YVsTxWZ","outputId":"3ff47b30-687e-4af3-d188-caaabd0df668"},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 2000/2000 [04:19<00:00,  7.70it/s]","output_type":"stream"},{"name":"stdout","text":"\n\nmean F1:  49.82883214941282\n\n\nmean EM:  21.6\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":["## Answer Generator Model\n","\n","A brief summary of our ensamble up to this point:\n","- Machine Learning model to filter yes-or-no question from open question\n","- Model for ExtractiveQA to find the span of the answer of open question\n","\n","And now, we just need to \"re-arrange\" the span of the answer to generate the final correct answer.\n","\n","More precisely, our objective is in between paraphrasing and summarizing the extracted span to generate the answer.\n","\n","The nature of this problem is the same as our first Generative QA approach, so we decided to utilize the same T5 architecture."],"metadata":{"id":"wRMHXe7DTxWa"}},{"cell_type":"code","source":["# Copy the original train set, if needed, it can be reduced\n","df_gqa = df_train_qa.copy()\n","\n","# Remove yes/no questions\n","df_gqa = df_gqa.drop(df_gqa[df_gqa['y'] == 1].index)\n","\n","# Remove y column\n","df_gqa = df_gqa.drop(['y'], axis=1)\n","\n","# Perform the split\n","df_train_gqa, df_val_gqa = train_val_split(df_gqa, 0.8, True)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:07.600767Z","iopub.execute_input":"2023-02-09T13:37:07.601150Z","iopub.status.idle":"2023-02-09T13:37:07.690062Z","shell.execute_reply.started":"2023-02-09T13:37:07.601120Z","shell.execute_reply":"2023-02-09T13:37:07.689072Z"},"trusted":true,"id":"HbBV0j1DTxWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hg_ds_gqa = convert_to_hg_dataset(['story_id', 'story', 'R1_start', 'R1_end'], df_train_gqa, df_val_gqa)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:07.692095Z","iopub.execute_input":"2023-02-09T13:37:07.692554Z","iopub.status.idle":"2023-02-09T13:37:07.738786Z","shell.execute_reply.started":"2023-02-09T13:37:07.692517Z","shell.execute_reply":"2023-02-09T13:37:07.737870Z"},"trusted":true,"id":"wW3duFgFTxWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_checkpoint_gqa = \"t5-small\"\n","tokenizer_gqa = AutoTokenizer.from_pretrained(model_checkpoint_gqa)\n","model_gqa = TFT5ForConditionalGeneration.from_pretrained(model_checkpoint_gqa)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:07.740376Z","iopub.execute_input":"2023-02-09T13:37:07.740720Z","iopub.status.idle":"2023-02-09T13:37:10.011372Z","shell.execute_reply.started":"2023-02-09T13:37:07.740686Z","shell.execute_reply":"2023-02-09T13:37:10.010385Z"},"trusted":true,"id":"sXEvtxabTxWa","outputId":"09d54a7a-955b-4187-f041-98ac0831ff39"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:165: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  FutureWarning,\nAll model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n\nAll the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"TFUVzCtaTxWb"}},{"cell_type":"code","source":["max_input_length = 512\n","max_target_length = 128\n","\n","\n","def preprocess_function_gqa(examples):\n","    inputs = 'question: %s  context: %s' % (examples['question'], examples['R1'])\n","    model_inputs = tokenizer_gqa(inputs, max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer_gqa.as_target_tokenizer():\n","        labels = tokenizer_gqa(\n","            examples[\"answer\"], max_length=max_target_length, truncation=True\n","        )\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:10.014993Z","iopub.execute_input":"2023-02-09T13:37:10.015319Z","iopub.status.idle":"2023-02-09T13:37:10.021492Z","shell.execute_reply.started":"2023-02-09T13:37:10.015292Z","shell.execute_reply":"2023-02-09T13:37:10.020470Z"},"trusted":true,"id":"k7eU_DMZTxWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets_gqa = hg_ds_gqa.map(preprocess_function_gqa, remove_columns=hg_ds_gqa[\"train\"].column_names)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:10.023115Z","iopub.execute_input":"2023-02-09T13:37:10.024006Z","iopub.status.idle":"2023-02-09T13:37:45.743864Z","shell.execute_reply.started":"2023-02-09T13:37:10.023789Z","shell.execute_reply":"2023-02-09T13:37:45.743017Z"},"trusted":true,"colab":{"referenced_widgets":["f481543159a040bdad2eb625018b8f5e","b9103fe743cf4b309613c72cd401120b"]},"id":"oDC7y9mCTxWb","outputId":"e2cbb27e-4edb-47c0-8eff-c93e47141508"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/69069 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f481543159a040bdad2eb625018b8f5e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3582: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17294 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9103fe743cf4b309613c72cd401120b"}},"metadata":{}}]},{"cell_type":"code","source":["tokenized_datasets_gqa"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:45.745448Z","iopub.execute_input":"2023-02-09T13:37:45.746156Z","iopub.status.idle":"2023-02-09T13:37:45.753564Z","shell.execute_reply.started":"2023-02-09T13:37:45.746115Z","shell.execute_reply":"2023-02-09T13:37:45.752515Z"},"trusted":true,"id":"KSusVYVUTxWb","outputId":"6945cd11-4fd1-49db-a0d8-99b29f131af2"},"execution_count":null,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 69069\n    })\n    val: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 17294\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":["idx = 42\n","print(tokenizer_gqa.decode(tokenized_datasets_gqa[\"train\"]['input_ids'][idx]))\n","print(\"\\n\\n\",tokenizer_gqa.decode(tokenized_datasets_gqa[\"train\"]['labels'][idx]))\n","\n","print(\"\\n\\n\",tokenized_datasets_gqa[\"train\"]['input_ids'][idx])\n","print(\"\\n\\n\",tokenized_datasets_gqa[\"train\"]['labels'][idx])"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:45.755149Z","iopub.execute_input":"2023-02-09T13:37:45.756299Z","iopub.status.idle":"2023-02-09T13:37:48.683122Z","shell.execute_reply.started":"2023-02-09T13:37:45.756205Z","shell.execute_reply":"2023-02-09T13:37:48.681992Z"},"trusted":true,"id":"xU8YOdtMTxWb","outputId":"4a02cd96-57c4-4550-f7a0-205b9618f0cd"},"execution_count":null,"outputs":[{"name":"stdout","text":"question: What Island does he travel to? context: After ending up on the Island of Misfit Toys</s>\n\n\n the Island of Misfit Toys</s>\n\n\n [822, 10, 363, 2834, 405, 3, 88, 1111, 12, 58, 2625, 10, 621, 7784, 95, 30, 8, 2834, 13, 8306, 5616, 304, 63, 7, 1]\n\n\n [8, 2834, 13, 8306, 5616, 304, 63, 7, 1]\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### Fine-tuning the model"],"metadata":{"id":"GXLdHjd0TxWc"}},{"cell_type":"code","source":["# Hyperparams\n","learning_rate = 2e-4 #1e-4\n","num_train_epochs = 1\n","weight_decay = 0.01\n","batch_size = 8\n","\n","optimizer = AdamWeightDecay(learning_rate=learning_rate,\n","                            weight_decay_rate=weight_decay,)\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer_gqa, model=model_gqa, return_tensors=\"np\")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:48.684786Z","iopub.execute_input":"2023-02-09T13:37:48.685187Z","iopub.status.idle":"2023-02-09T13:37:48.692110Z","shell.execute_reply.started":"2023-02-09T13:37:48.685147Z","shell.execute_reply":"2023-02-09T13:37:48.690812Z"},"trusted":true,"id":"1SxAP7hNTxWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set_gqa = model_gqa.prepare_tf_dataset(\n","    tokenized_datasets_gqa[\"train\"],\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=data_collator,\n",")\n","\n","val_set_gqa = model_gqa.prepare_tf_dataset(\n","    tokenized_datasets_gqa[\"val\"],\n","    batch_size=batch_size,\n","    shuffle=False,\n","    collate_fn=data_collator,\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:48.693763Z","iopub.execute_input":"2023-02-09T13:37:48.695105Z","iopub.status.idle":"2023-02-09T13:37:48.777704Z","shell.execute_reply.started":"2023-02-09T13:37:48.695062Z","shell.execute_reply":"2023-02-09T13:37:48.776770Z"},"trusted":true,"id":"LrkSvFcdTxWc","outputId":"b48c4667-1523-4713-d456-3fca7c4b6c13"},"execution_count":null,"outputs":[{"name":"stderr","text":"You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"}]},{"cell_type":"code","source":["# Compile the model\n","model_gqa.compile(optimizer=optimizer)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:48.782123Z","iopub.execute_input":"2023-02-09T13:37:48.782405Z","iopub.status.idle":"2023-02-09T13:37:48.794952Z","shell.execute_reply.started":"2023-02-09T13:37:48.782379Z","shell.execute_reply":"2023-02-09T13:37:48.793892Z"},"trusted":true,"id":"KlagWwNcTxWc","outputId":"d80b7d16-83f7-4faf-aedc-ecd9c745e69e"},"execution_count":null,"outputs":[{"name":"stderr","text":"No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n","output_type":"stream"}]},{"cell_type":"code","source":["# Train the model\n","model_gqa.fit(\n","    x=train_set_gqa,\n","    validation_data=val_set_gqa,\n","    epochs=num_train_epochs\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:37:48.796497Z","iopub.execute_input":"2023-02-09T13:37:48.796927Z","iopub.status.idle":"2023-02-09T13:54:25.133334Z","shell.execute_reply.started":"2023-02-09T13:37:48.796890Z","shell.execute_reply":"2023-02-09T13:54:25.132123Z"},"trusted":true,"id":"xhOgkNbZTxWc","outputId":"44c841e6-18d1-49fc-8b35-f232961271ca"},"execution_count":null,"outputs":[{"name":"stdout","text":"8633/8633 [==============================] - 940s 107ms/step - loss: 0.7886 - val_loss: 0.6905\n","output_type":"stream"},{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f044ac43110>"},"metadata":{}}]},{"cell_type":"markdown","source":["### Inference"],"metadata":{"id":"v6oT7ngzTxWd"}},{"cell_type":"code","source":["idx = 42\n","\n","input_text =  f\"question: {df_val_gqa['question'][idx]} context: {df_val_gqa['R1'][idx]}\"\n","\n","input_tokenized = tokenizer_gqa(input_text, return_tensors='np', pad_to_max_length=True, truncation=True, max_length=512)\n","\n","input_ids = input_tokenized.input_ids\n","attention_mask = input_tokenized.attention_mask\n","\n","model_answer = model_gqa.generate(input_ids)#, num_beams=4, length_penalty= 1.5, no_repeat_ngram_size=2)\n","\n","print(\"\\nQuestion: \", df_val_gqa['question'][idx], \"\\n\\n\")\n","print(\"R1: \\t\\t\", df_val_gqa['R1'][idx])\n","print(\"\\n\\nModel answer:  \\t\",tokenizer_gqa.decode(model_answer[0], skip_special_tokens=True))\n","print(\"\\nReal answer: \\t\",df_val_gqa['answer'][idx])"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:54:25.135012Z","iopub.execute_input":"2023-02-09T13:54:25.136224Z","iopub.status.idle":"2023-02-09T13:54:25.399058Z","shell.execute_reply.started":"2023-02-09T13:54:25.136177Z","shell.execute_reply":"2023-02-09T13:54:25.398023Z"},"trusted":true,"id":"i5OraQqPTxWd","outputId":"3029d8b2-ae4e-4137-d617-0ff4f404949f"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2345: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n/opt/conda/lib/python3.7/site-packages/transformers/generation/tf_utils.py:707: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  UserWarning,\n","output_type":"stream"},{"name":"stdout","text":"\nQuestion:  How many wolves were initially following him? \n\n\nR1: \t\t It was a long way from my friend's house when about twenty wolves began to follow my sleigh\n\n\nModel answer:  \t twenty\n\nReal answer: \t About twenty\n","output_type":"stream"}]},{"cell_type":"code","source":["n_samples = 2000\n","test_eval_subset = df_test_qa.sample(n = n_samples, random_state = seed).reset_index()\n","f1s = []\n","ems = []\n","\n","for idx in tqdm(range(n_samples)):\n","      \n","    input_text =  f\"question: {test_eval_subset['question'][idx]} context: {test_eval_subset['R1'][idx]}\"\n","    inputs = tokenizer_gqa(input_text, return_tensors='np', pad_to_max_length=True, truncation=True, max_length=512)\n","    input_ids = inputs.input_ids\n","\n","    outputs = model_gqa.generate(input_ids)\n","\n","    ref_text = test_eval_subset['answer'][idx]\n","    ref_start = test_eval_subset['R1_start'][idx]\n","\n","    # Decode the answer\n","    answer = tokenizer_gqa.decode(outputs[0], skip_special_tokens=True)\n","    \n","    predictions = [{'prediction_text': answer, 'id': '1'}]\n","    references = [{'answers': {'answer_start': [ref_start], 'text': [ref_text]}, 'id': '1'}]\n","    results = squad_metric.compute(predictions=predictions, references=references)\n","    f1s.append(results['f1'])\n","    ems.append(results['exact_match'])\n","\n","print(\"\\n\\nmean F1: \", np.mean(f1s))\n","print(\"\\n\\nmean EM: \", np.mean(ems))"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:54:25.400618Z","iopub.execute_input":"2023-02-09T13:54:25.400978Z","iopub.status.idle":"2023-02-09T14:11:57.952952Z","shell.execute_reply.started":"2023-02-09T13:54:25.400942Z","shell.execute_reply":"2023-02-09T14:11:57.951074Z"},"trusted":true,"id":"yPU8q8jQTxWd","outputId":"18155e6a-a91a-492c-d2a0-558564b0e853"},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 2000/2000 [17:32<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"\n\nmean F1:  64.88787973514931\n\n\nmean EM:  51.9\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":["## Boolean QA\n","\n","First, we need to adjust our dataset, in our case we just need the yes-or-no questions and a new column, that we called `yes-no` which represent the answer in boolean format.\n","\n","The same dataframe manipulation is also applied to the test dataset."],"metadata":{"id":"gel3t4MRTxWd"}},{"cell_type":"code","source":["# Take a copy of the train set with only yes-or-no questions\n","df_train_qa_yn = df_train_qa[df_train_qa['y'] == 1].copy()\n","\n","# Lower the answer to better process \n","df_train_qa_yn['answer'] = df_train_qa_yn['answer'].apply(str.lower)\n","\n","# Set as 1 yes and 0 no answers\n","df_train_qa_yn['yes-no'] = df_train_qa_yn.apply(lambda x: 1 if(x['answer'] == 'yes' or x['answer'] == 'yes.') else 0, axis=1)\n","\n","# Drop the now useless y column\n","df_train_qa_yn = df_train_qa_yn.drop(['y'], axis = 1)\n","\n","# Reset the index\n","df_train_qa_yn = df_train_qa_yn.reset_index(drop=True)\n","\n","df_train_qa_yn"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:28.411253Z","iopub.execute_input":"2023-02-09T14:45:28.411957Z","iopub.status.idle":"2023-02-09T14:45:28.676517Z","shell.execute_reply.started":"2023-02-09T14:45:28.411923Z","shell.execute_reply":"2023-02-09T14:45:28.675405Z"},"trusted":true,"id":"rXoJ6XPUTxWd","outputId":"21973221-26e6-41a5-a65e-1dc48ea5c3e4"},"execution_count":null,"outputs":[{"execution_count":171,"output_type":"execute_result","data":{"text/plain":"       story_id                                              story  \\\n0             2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n1             2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n2             2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n3             2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n4             2  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n...         ...                                                ...   \n20918      7197  Frankfurt, officially Frankfurt am Main (Liter...   \n20919      7197  Frankfurt, officially Frankfurt am Main (Liter...   \n20920      7197  Frankfurt, officially Frankfurt am Main (Liter...   \n20921      7198  (CNN) -- Cristiano Ronaldo provided the perfec...   \n20922      7198  (CNN) -- Cristiano Ronaldo provided the perfec...   \n\n                                         question  R1_start  R1_end  \\\n0                                   Did he agree?        99     129   \n1                       Did she tell him as much?       307     360   \n2         Did she allow herself to even think it?       640     666   \n3      Did Jane think she could control Lassiter?      1141    1205   \n4          Was Lassiter impressed with the horse?      1360    1450   \n...                                           ...       ...     ...   \n20918           Does the city have tech startups?      1279    1313   \n20919                                Is it large?      1522    1580   \n20920                      Is there a music fair?      1659    1673   \n20921                      Was Bale 25 years old?      1235    1259   \n20922            Was it his first game this year?      1415    1467   \n\n                                                      R1 answer  yes-no  \n0                         \"I reckon so,\" he had replied.    yes       1  \n1      though she could not have spoken aloud all she...     no       0  \n2                             she did not even think it.     no       0  \n3      If she could not wholly control Lassiter, then...     no       0  \n4      When Jerd led out this slender, beautifully bu...    yes       1  \n...                                                  ...    ...     ...  \n20918                 several cloud and fintech startups    yes       1  \n20919  Messe Frankfurt is one of the world's largest ...    yes       1  \n20920                                     the Music Fair    yes       1  \n20921                           faith in the 24-year-old     no       0  \n20922   Xabi Alonso made his first appearance of the ...    yes       1  \n\n[20923 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>story</th>\n      <th>question</th>\n      <th>R1_start</th>\n      <th>R1_end</th>\n      <th>R1</th>\n      <th>answer</th>\n      <th>yes-no</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n      <td>Did he agree?</td>\n      <td>99</td>\n      <td>129</td>\n      <td>\"I reckon so,\" he had replied.</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n      <td>Did she tell him as much?</td>\n      <td>307</td>\n      <td>360</td>\n      <td>though she could not have spoken aloud all she...</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n      <td>Did she allow herself to even think it?</td>\n      <td>640</td>\n      <td>666</td>\n      <td>she did not even think it.</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n      <td>Did Jane think she could control Lassiter?</td>\n      <td>1141</td>\n      <td>1205</td>\n      <td>If she could not wholly control Lassiter, then...</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n      <td>Was Lassiter impressed with the horse?</td>\n      <td>1360</td>\n      <td>1450</td>\n      <td>When Jerd led out this slender, beautifully bu...</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20918</th>\n      <td>7197</td>\n      <td>Frankfurt, officially Frankfurt am Main (Liter...</td>\n      <td>Does the city have tech startups?</td>\n      <td>1279</td>\n      <td>1313</td>\n      <td>several cloud and fintech startups</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20919</th>\n      <td>7197</td>\n      <td>Frankfurt, officially Frankfurt am Main (Liter...</td>\n      <td>Is it large?</td>\n      <td>1522</td>\n      <td>1580</td>\n      <td>Messe Frankfurt is one of the world's largest ...</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20920</th>\n      <td>7197</td>\n      <td>Frankfurt, officially Frankfurt am Main (Liter...</td>\n      <td>Is there a music fair?</td>\n      <td>1659</td>\n      <td>1673</td>\n      <td>the Music Fair</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20921</th>\n      <td>7198</td>\n      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n      <td>Was Bale 25 years old?</td>\n      <td>1235</td>\n      <td>1259</td>\n      <td>faith in the 24-year-old</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20922</th>\n      <td>7198</td>\n      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n      <td>Was it his first game this year?</td>\n      <td>1415</td>\n      <td>1467</td>\n      <td>Xabi Alonso made his first appearance of the ...</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>20923 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["df_train_yn, df_val_yn = train_val_split(df_train_qa_yn, 0.8, True)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:28.678362Z","iopub.execute_input":"2023-02-09T14:45:28.679611Z","iopub.status.idle":"2023-02-09T14:45:28.699439Z","shell.execute_reply.started":"2023-02-09T14:45:28.679574Z","shell.execute_reply":"2023-02-09T14:45:28.698590Z"},"trusted":true,"id":"m_8KQBdJTxWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Take a copy of the test set with only yes-or-no questions\n","df_test_yn = df_test_qa[df_test_qa['y'] == 1].copy()\n","\n","# Lower the answer to better process \n","df_test_yn['answer'] = df_test_yn['answer'].apply(str.lower)\n","\n","# Set as 1 yes and 0 no answers\n","df_test_yn['yes-no'] = df_test_yn.apply(lambda x: 1 if(x['answer'] == 'yes' or x['answer'] == 'yes.') else 0, axis=1)\n","\n","# Drop the now useless y column\n","df_test_yn = df_test_yn.drop(['y'], axis = 1)\n","\n","# Reset the index\n","df_test_yn = df_test_yn.reset_index(drop=True)\n","\n","df_test_yn"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:28.700496Z","iopub.execute_input":"2023-02-09T14:45:28.700743Z","iopub.status.idle":"2023-02-09T14:45:28.741464Z","shell.execute_reply.started":"2023-02-09T14:45:28.700719Z","shell.execute_reply":"2023-02-09T14:45:28.740466Z"},"trusted":true,"id":"QqUXM019TxWe","outputId":"a08f63da-392e-4af2-8039-3dc3f1bc9868"},"execution_count":null,"outputs":[{"execution_count":173,"output_type":"execute_result","data":{"text/plain":"      story_id                                              story  \\\n0            0  Once upon a time, in a barn near a farm house,...   \n1            0  Once upon a time, in a barn near a farm house,...   \n2            0  Once upon a time, in a barn near a farm house,...   \n3            1  Once there was a beautiful fish named Asta. As...   \n4            1  Once there was a beautiful fish named Asta. As...   \n...        ...                                                ...   \n1608       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n1609       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n1610       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n1611       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n1612       499  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n\n                                               question  R1_start  R1_end  \\\n0                                   Did she live alone?       196     215   \n1     Was Cotton happy that she looked different tha...       512     549   \n2     Did they want Cotton to change the color of he...       965    1008   \n3                                 Was Sharkie a friend?       281     302   \n4                              did they get the bottle?       552     577   \n...                                                 ...       ...     ...   \n1608        Is it a popular spot for business meetings?       750     826   \n1609             Does it have many Five Diamond hotels?       876     946   \n1610                Is it a popular tourist desination?       955    1036   \n1611                         Is it located in a desert?       326     358   \n1612                                is it a small city?       161     207   \n\n                                                     R1 answer  yes-no  \n0                                   Cotton wasn't alone     no       0  \n1                 Being different made Cotton quite sad     no       0  \n2           We would never want you to be any other way     no       0  \n3                                 Asta's friend Sharkie    yes       1  \n4                             So they caught the bottle    yes       1  \n...                                                 ...    ...     ...  \n1608   It is a top three destination in the United S...    yes       1  \n1609  claiming more AAA Five Diamond hotels than any...    yes       1  \n1610  Las Vegas annually ranks as one of the world's...    yes       1  \n1611                   within the greater Mojave Desert    yes       1  \n1612     the most populated city in the state of Nevada     no       0  \n\n[1613 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>story</th>\n      <th>question</th>\n      <th>R1_start</th>\n      <th>R1_end</th>\n      <th>R1</th>\n      <th>answer</th>\n      <th>yes-no</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Once upon a time, in a barn near a farm house,...</td>\n      <td>Did she live alone?</td>\n      <td>196</td>\n      <td>215</td>\n      <td>Cotton wasn't alone</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Once upon a time, in a barn near a farm house,...</td>\n      <td>Was Cotton happy that she looked different tha...</td>\n      <td>512</td>\n      <td>549</td>\n      <td>Being different made Cotton quite sad</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Once upon a time, in a barn near a farm house,...</td>\n      <td>Did they want Cotton to change the color of he...</td>\n      <td>965</td>\n      <td>1008</td>\n      <td>We would never want you to be any other way</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Once there was a beautiful fish named Asta. As...</td>\n      <td>Was Sharkie a friend?</td>\n      <td>281</td>\n      <td>302</td>\n      <td>Asta's friend Sharkie</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Once there was a beautiful fish named Asta. As...</td>\n      <td>did they get the bottle?</td>\n      <td>552</td>\n      <td>577</td>\n      <td>So they caught the bottle</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1608</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>Is it a popular spot for business meetings?</td>\n      <td>750</td>\n      <td>826</td>\n      <td>It is a top three destination in the United S...</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1609</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>Does it have many Five Diamond hotels?</td>\n      <td>876</td>\n      <td>946</td>\n      <td>claiming more AAA Five Diamond hotels than any...</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1610</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>Is it a popular tourist desination?</td>\n      <td>955</td>\n      <td>1036</td>\n      <td>Las Vegas annually ranks as one of the world's...</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1611</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>Is it located in a desert?</td>\n      <td>326</td>\n      <td>358</td>\n      <td>within the greater Mojave Desert</td>\n      <td>yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1612</th>\n      <td>499</td>\n      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n      <td>is it a small city?</td>\n      <td>161</td>\n      <td>207</td>\n      <td>the most populated city in the state of Nevada</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1613 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":["As previously stated, this problem can be dealt as a classification one, so it was utilized the `SequenceClassification` class.\n","\n","In our case the lable to assign are:\n","\n","- 0 = No\n","- 1 = Yes\n","\n","\n","For this part the [`distilroberta-base`](https://huggingface.co/distilroberta-base) model was chosen.\n","\n","As before, the right choice of model is up to debate, in this notebook `distilroberta-base` was chosen since the boolean QA was believed to be the easiest part of the ensamble and, in order to avoid excessive complexity, the distilled version of RoBERTa was a suitable candidate."],"metadata":{"id":"mx4PFGY6TxWe"}},{"cell_type":"code","source":["model_checkpoint_yn = \"distilroberta-base\"\n","tokenizer_yn = AutoTokenizer.from_pretrained(model_checkpoint_yn)\n","model_yn = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint_yn)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:28.744147Z","iopub.execute_input":"2023-02-09T14:45:28.744499Z","iopub.status.idle":"2023-02-09T14:45:30.462569Z","shell.execute_reply.started":"2023-02-09T14:45:28.744465Z","shell.execute_reply":"2023-02-09T14:45:30.461401Z"},"trusted":true,"id":"-50amHtKTxWe","outputId":"3dabb7ac-d5c2-41f5-9eae-950e8c2b4f61"},"execution_count":null,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n\nSome layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### Preprocessing"],"metadata":{"id":"5J_ImUZhTxWf"}},{"cell_type":"code","source":["hg_ds_yn = convert_to_hg_dataset(['story_id', 'R1', 'R1_start', 'R1_end', 'answer'], df_train_yn, df_val_yn)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:30.464560Z","iopub.execute_input":"2023-02-09T14:45:30.465386Z","iopub.status.idle":"2023-02-09T14:45:30.524002Z","shell.execute_reply.started":"2023-02-09T14:45:30.465322Z","shell.execute_reply":"2023-02-09T14:45:30.523009Z"},"trusted":true,"id":"EN1w0UY-TxWf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hg_ds_yn"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:30.525672Z","iopub.execute_input":"2023-02-09T14:45:30.526047Z","iopub.status.idle":"2023-02-09T14:45:30.532729Z","shell.execute_reply.started":"2023-02-09T14:45:30.526011Z","shell.execute_reply":"2023-02-09T14:45:30.531710Z"},"trusted":true,"id":"SgUPp7hWTxWf","outputId":"773c4b96-b050-41e9-ff5c-45da58476a56"},"execution_count":null,"outputs":[{"execution_count":176,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['story', 'question', 'yes-no'],\n        num_rows: 16699\n    })\n    val: Dataset({\n        features: ['story', 'question', 'yes-no'],\n        num_rows: 4224\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":["def preprocess_function_yn(examples):\n","    # Correctly format the inputs\n","    model_inputs = tokenizer_yn(examples['question'], examples['story'], truncation=\"only_second\")\n","\n","    model_inputs[\"labels\"] = examples[\"yes-no\"]\n","    return model_inputs"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:30.534424Z","iopub.execute_input":"2023-02-09T14:45:30.535146Z","iopub.status.idle":"2023-02-09T14:45:30.541822Z","shell.execute_reply.started":"2023-02-09T14:45:30.535110Z","shell.execute_reply":"2023-02-09T14:45:30.540795Z"},"trusted":true,"id":"n82AXlbRTxWf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets_yn = hg_ds_yn.map(preprocess_function_yn, remove_columns=hg_ds_yn[\"train\"].column_names, batched=True)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:30.543397Z","iopub.execute_input":"2023-02-09T14:45:30.544079Z","iopub.status.idle":"2023-02-09T14:45:52.412203Z","shell.execute_reply.started":"2023-02-09T14:45:30.544043Z","shell.execute_reply":"2023-02-09T14:45:52.411342Z"},"trusted":true,"colab":{"referenced_widgets":["f2136738fb374906aded2c38ad2b744c","6d877378757a405a88943615b96894a2"]},"id":"mrgZXqu8TxWf","outputId":"9af92b02-cb93-4b68-b640-3520cad79d4f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2136738fb374906aded2c38ad2b744c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d877378757a405a88943615b96894a2"}},"metadata":{}}]},{"cell_type":"markdown","source":["### Fine-tuning the model"],"metadata":{"id":"cyeID0e5TxWf"}},{"cell_type":"code","source":["# Training hyperparameters\n","\n","learning_rate = 2e-5 #1e-4\n","num_train_epochs = 1\n","weight_decay = 0.01\n","batch_size = 8\n","\n","optimizer = AdamWeightDecay(learning_rate = learning_rate,\n","                            weight_decay_rate = weight_decay,)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:52.416460Z","iopub.execute_input":"2023-02-09T14:45:52.418899Z","iopub.status.idle":"2023-02-09T14:45:52.425630Z","shell.execute_reply.started":"2023-02-09T14:45:52.418861Z","shell.execute_reply":"2023-02-09T14:45:52.424831Z"},"trusted":true,"id":"ZMy0T-9tTxWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set_yn = model_yn.prepare_tf_dataset(\n","    tokenized_datasets_yn[\"train\"],\n","    batch_size=batch_size,\n","    shuffle=True,\n","    tokenizer=tokenizer_yn\n",")\n","\n","val_set_yn = model_yn.prepare_tf_dataset(\n","    tokenized_datasets_yn[\"val\"],\n","    batch_size=batch_size,\n","    shuffle=False,\n","    tokenizer=tokenizer_yn\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:52.431835Z","iopub.execute_input":"2023-02-09T14:45:52.434515Z","iopub.status.idle":"2023-02-09T14:45:52.518547Z","shell.execute_reply.started":"2023-02-09T14:45:52.434478Z","shell.execute_reply":"2023-02-09T14:45:52.517731Z"},"trusted":true,"id":"tzbg8rc9TxWg","outputId":"edd9d3ed-7d24-4148-de2e-74670cb2c80d"},"execution_count":null,"outputs":[{"name":"stderr","text":"You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"}]},{"cell_type":"code","source":["# Compile the model\n","model_yn.compile(optimizer=optimizer)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:52.522513Z","iopub.execute_input":"2023-02-09T14:45:52.524608Z","iopub.status.idle":"2023-02-09T14:45:52.540791Z","shell.execute_reply.started":"2023-02-09T14:45:52.524574Z","shell.execute_reply":"2023-02-09T14:45:52.539877Z"},"trusted":true,"id":"rGaA2A4ITxWg","outputId":"180f1396-3a77-4f50-cd71-bd3e785ad0ff"},"execution_count":null,"outputs":[{"name":"stderr","text":"No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n","output_type":"stream"}]},{"cell_type":"code","source":["# Train the model\n","model_yn.fit(\n","    x=train_set_yn,\n","    validation_data=val_set_yn,\n","    epochs=num_train_epochs\n",")"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T14:45:52.542320Z","iopub.execute_input":"2023-02-09T14:45:52.542677Z","iopub.status.idle":"2023-02-09T15:03:36.134250Z","shell.execute_reply.started":"2023-02-09T14:45:52.542644Z","shell.execute_reply":"2023-02-09T15:03:36.133243Z"},"trusted":true,"id":"VvbijHMHTxWh","outputId":"4f95e474-26a9-4103-c5e2-596f1da891cc"},"execution_count":null,"outputs":[{"name":"stdout","text":"2087/2087 [==============================] - 1064s 506ms/step - loss: 0.6532 - val_loss: 0.5269\n","output_type":"stream"},{"execution_count":182,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f040ac9bb10>"},"metadata":{}}]},{"cell_type":"markdown","source":["### Inference"],"metadata":{"id":"2HUBdAg4TxWh"}},{"cell_type":"code","source":["idx = 123\n","\n","tokenized = tokenizer_yn(df_val_yn['question'][idx], df_val_yn['story'][idx], return_tensors=\"np\", truncation=\"only_second\")\n","\n","outputs = model_yn(tokenized).logits\n","\n","classifications = np.argmax(outputs, axis=1)\n","print(\"Question:\\n\", df_val_yn['question'][idx])\n","print(\"\\nReal answer:\\n\", df_val_yn['answer'][idx])\n","print(\"\\nModel answer:\\n\",classifications)\n","print(outputs)"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T15:03:36.135572Z","iopub.execute_input":"2023-02-09T15:03:36.135947Z","iopub.status.idle":"2023-02-09T15:03:36.213177Z","shell.execute_reply.started":"2023-02-09T15:03:36.135908Z","shell.execute_reply":"2023-02-09T15:03:36.212058Z"},"trusted":true,"id":"R1mauAxzTxWh","outputId":"901544b8-8c52-4c18-c2b8-50a6a5077a0f"},"execution_count":null,"outputs":[{"name":"stdout","text":"Question:\n Is his mom Mrs. Massanet?\n\nReal answer:\n no\n\nModel answer:\n [0]\ntf.Tensor([[ 0.4900276 -0.5386593]], shape=(1, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":["accuracy_score = load('accuracy')\n","\n","predictions = []\n","true = []\n","\n","for idx in tqdm(range(df_test_yn.shape[0])):\n","    inputs = tokenizer_yn(df_test_yn['question'][idx], df_test_yn['story'][idx], return_tensors=\"np\", truncation=\"only_second\")\n","    \n","    outputs = model_yn(inputs).logits\n","    classification = np.argmax(outputs, axis=1)\n","    \n","    predictions.append(classification[0])\n","    true.append(df_test_yn['yes-no'][idx])\n","    \n","accuracy_score.compute(predictions=predictions, references=true)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T15:03:36.214883Z","iopub.execute_input":"2023-02-09T15:03:36.215517Z","iopub.status.idle":"2023-02-09T15:05:26.130113Z","shell.execute_reply.started":"2023-02-09T15:03:36.215474Z","shell.execute_reply":"2023-02-09T15:05:26.129040Z"},"trusted":true,"id":"zjnRHC6hTxWh","outputId":"bd4f8507-7f10-4a2d-a078-6aa21e57fc7d"},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 1613/1613 [01:49<00:00, 14.73it/s]\n","output_type":"stream"},{"execution_count":184,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.7067575945443273}"},"metadata":{}}]},{"cell_type":"markdown","source":["## Create the ensamble"],"metadata":{"id":"V7riJLQkTxWh"}},{"cell_type":"code","source":["def ensamble_model(context, question):\n","    \n","    max_length = 1024\n","    \n","    predicted_type = gs_svm.predict([question])\n","    \n","    # yes-or-no\n","    if predicted_type == 1:\n","        # Format the input\n","        inputs_yn = tokenizer_yn(question, context, return_tensors=\"np\", truncation=\"only_second\")\n","        # Get the output\n","        outputs = model_yn(inputs_yn).logits\n","        result = np.argmax(outputs, axis=1)\n","        \n","        if result == 1:\n","            return \"Yes\"\n","        elif result == 0:\n","            return \"No\" \n","    \n","    # Open question\n","    elif predicted_type == 0:\n","        # Format the input\n","        inputs_span = tokenizer_span([question], [context], return_tensors=\"np\", truncation=\"only_second\", max_length=max_length,)\n","        # Get the output\n","        outputs = model_span(inputs_span)\n","        start_position = np.argmax(outputs.start_logits[0])\n","        end_position = np.argmax(outputs.end_logits[0])\n","        # Extract this substring from the inputs\n","        extracted_span = inputs_span[\"input_ids\"][0, start_position:end_position + 1]\n","        # Decode the answer\n","        extracted_span = tokenizer_span.decode(extracted_span)\n","        \n","        # Process the input\n","        input_text =  f\"question: {question} context: {extracted_span}\"\n","        inputs = tokenizer_gqa(input_text, return_tensors='np', pad_to_max_length=True, truncation=True, max_length=512)\n","        input_ids = inputs.input_ids\n","        # Generate the answer\n","        outputs = model_gqa.generate(input_ids)\n","        # Decode the answer\n","        answer = tokenizer_gqa.decode(outputs[0], skip_special_tokens=True)\n","        \n","        return answer\n"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T15:10:43.607428Z","iopub.execute_input":"2023-02-09T15:10:43.607894Z","iopub.status.idle":"2023-02-09T15:10:43.622666Z","shell.execute_reply.started":"2023-02-09T15:10:43.607853Z","shell.execute_reply":"2023-02-09T15:10:43.620773Z"},"trusted":true,"id":"vj6DHjCCTxWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_eval_subset = df_test_qa.sample(n = n_samples, random_state = seed).reset_index()\n","idx = 123\n","idx2 = 722\n","    \n","print(\"Question: \", test_eval_subset['question'][idx])\n","print(\"\\nReal Answer: \", test_eval_subset['answer'][idx])\n","print(\"\\nModel Answer: \", ensamble_model(test_eval_subset['story'][idx], test_eval_subset['question'][idx]))\n","\n","print(\"-\"*40)\n","\n","print(\"\\nQuestion: \", test_eval_subset['question'][idx2])\n","print(\"\\nReal Answer: \", test_eval_subset['answer'][idx2])\n","print(\"\\nModel Answer: \", ensamble_model(test_eval_subset['story'][idx2], test_eval_subset['question'][idx2]))\n","\n","print(\"-\"*40)\n","\n","print(\"\\nContext: \", test_eval_subset['story'][700])\n","print(\"\\nQuestion: \", test_eval_subset['question'][700])\n","print(\"\\nReal Answer: \", test_eval_subset['answer'][700])\n","print(\"\\nModel Answer: \", ensamble_model(test_eval_subset['story'][700], test_eval_subset['question'][700]))"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T17:47:03.247156Z","iopub.execute_input":"2023-02-09T17:47:03.248398Z","iopub.status.idle":"2023-02-09T17:47:05.525649Z","shell.execute_reply.started":"2023-02-09T17:47:03.248334Z","shell.execute_reply":"2023-02-09T17:47:05.524504Z"},"trusted":true,"id":"eDReJ6A1TxWi","outputId":"d5c4358e-66a9-42b3-dfcf-9e9dd219d74c"},"execution_count":null,"outputs":[{"name":"stdout","text":"Question:  is another movie he is in mentioned?\n\nReal Answer:  YEs.\n\nModel Answer:  Yes\n----------------------------------------\n\nQuestion:  What is it called in Hebrew?\n\nReal Answer:  Milhemet Sheshet Ha Yamim\n\nModel Answer:  milhemet sheshet ha yamim\"\n----------------------------------------\n\nContext:  (CNN) -- Each year, Grammy Week offers up a full calendar of events -- each one boasting a guest list more spectacular than the next. But this year, the most coveted ticket was Friday night's \"2013 MusiCares Person of the Year Tribute\" honoring Bruce Springsteen. \n\nThe evening's entertainment featured six Rock and Roll Hall of Famers, a few critically acclaimed young artists -- and The Boss himself. \n\nNeil Young and Crazy Horse turned up the volume with a spirited version of \"Born in the U.S.A,\" flanked by a pair of cheerleaders with the letter \"S\" emblazoned on their sweaters. Colombian superstar Juanes put a bilingual spin on \"Hungry Heart,\" singing verses in both Spanish and English, and John Legend transformed \"Dancing in the Dark\" into a jazzy piano ballad, which led Springsteen to later remark that \"he made me sound like Gershwin. I love that.\" \n\nOther standout performances included Mumford & Sons' banjo-laced cover of \"I'm on Fire,\" Tom Morello and Jim James' mesmerizing take on \"The Ghost of Tom Joad,\" and country superstar Kenny Chesney's quietly effective rendition of \"One Step Up.\" \n\nElton John also opted for simplicity, accompanied only by his piano on \"Streets of Philadelphia.\" But the most curious vocal of the night was on \"Lonesome Day,\" where Sting exhibited a raspy growl that suggested he was looking to honor Springsteen by sounding like him. \n\nThe evening was part all-star concert, part fundraiser to benefit the MusiCares Foundation, the Recording Academy's philanthropic arm that provides assistance to members of the music industry. \n\nQuestion:  Who was he probably trying to pay homage to?\n\nReal Answer:  yes\n\nModel Answer:  bruce springsteen\n","output_type":"stream"}]},{"cell_type":"code","source":["squad_metric = load(\"squad\")\n","\n","n_samples = 1000\n","f1s = []\n","ems = []\n","\n","for idx in tqdm(range(n_samples)):\n","      \n","    # Generate the answer\n","    answer = ensamble_model(test_eval_subset['story'][idx], test_eval_subset['question'][idx])\n","\n","    ref_text = test_eval_subset['answer'][idx]\n","    ref_start = test_eval_subset['R1_start'][idx]\n","    \n","    predictions = [{'prediction_text': answer, 'id': '1'}]\n","    references = [{'answers': {'answer_start': [ref_start], 'text': [ref_text]}, 'id': '1'}]\n","    results = squad_metric.compute(predictions=predictions, references=references)\n","    f1s.append(results['f1'])\n","    ems.append(results['exact_match'])\n","\n","print(\"\\n\\nmean F1: \", np.mean(f1s))\n","print(\"\\n\\nmean EM: \", np.mean(ems))"],"metadata":{"execution":{"iopub.status.busy":"2023-02-09T15:16:29.097233Z","iopub.execute_input":"2023-02-09T15:16:29.097799Z","iopub.status.idle":"2023-02-09T15:25:30.684863Z","shell.execute_reply.started":"2023-02-09T15:16:29.097756Z","shell.execute_reply":"2023-02-09T15:25:30.683734Z"},"trusted":true,"id":"TqpDh0gKTxWi","outputId":"ba8baa0f-072a-42eb-ef63-631fad0a80a8"},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [09:00<00:00,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"\n\nmean F1:  55.44076754686662\n\n\nmean EM:  44.2\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":["# Conclusions\n","\n","## Results analysis\n","\n","### T5\n","\n","- mean F1:  54.72581772847185\n","\n","- mean EM:  43.9\n","\n","- Total Time = 2751s | 46m\n","\n","### Ensamble\n","\n","- mean F1:  55.44076754686662\n","\n","- mean EM:  44.2\n","\n","- Total Time = 4550s | 1h 15m\n","\n","### Simple Encoder-Decoder\n","\n","- mean F1:  0.14790483405483407\n","\n","- Total Time = 2453s | 41m\n","\n","## SoTA Comparison\n","\n","The current [state of the art](https://paperswithcode.com/sota/generative-question-answering-on-coqa), unfortunately, does not have a large number of papers associated with the Generative QA task on CoQA.\n","\n","Nonetheless, our ensamble approach is actually an improvement over the original CoQA paper, reaching our 55.4 F1 score over their 45.4.\n","\n","The current SoTA paper reaches an F1 score of 84.5 using a fine crafted model, trained in addition on extra data, which can perform a variety of tasks such as summarization of dialog generation.\n","\n","## Comments\n","\n","At the end, performance were particularly similar, having the ensamble being effectively a bit more accurate.\n","\n","However, this result does not prove that this ensamble could actually outperform the original T5 approach, since the two network had different training time.\n","\n","We had to limit the subset of samples on the T5 approach due to the limitation of our environment but, nevertheless, it managed to achieve similar high performance with more samples and less training time with respect to the Extractive QA.\n","\n","The most computational demanding part of the ensamble was the Extractive QA part, which required the most amount of training and inevitably was the main responsable for the ensamble performance.\n","\n","A clear advantage was found with respect to the normal Encoder-Decoder approach used in the NLP assignment. At that time we were limited in using the `EncoderDecoder` module of huggingface initialized for sequence-to-sequence approach and the `distillroberta` model.\n","Due to the complexity of the problem, this latter approach did not provide any good result.\n","\n","The ensamble approach, as was proven in many other deep learning fields, showed to be a huge improvement with respect to these simpler approaches.\n","\n","## Future Development\n","\n","Newer approaches such as T5 proved to be quite performing, clearly being the better alternative to our ensamble which, even if it performed quite well, the complexity and the training time required outweighted its accuracy.\n","\n","However, the ensamble could still be quite improved by:\n","- Finding better hyperparameters\n","- Changing different models\n","- Provide the history of the questions-answers to the model\n","- Testing it performance on the SQuAD dataset\n"],"metadata":{"id":"dzSKh1lcTxWi"}}]}